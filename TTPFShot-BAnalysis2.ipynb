{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32777b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pprint\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825666c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path='../Paper1-RAGG/impl/.env')\n",
    "\n",
    "### OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a04e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hamzicd/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc7687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2969986b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64707008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d7e0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d40eab6e",
   "metadata": {},
   "source": [
    "### Load and Test FewShotTTP (TTPFShot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76b41358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3800975/3801564067.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings2 = HuggingFaceEmbeddings(model_name = model2)\n",
      "No sentence-transformers model found with name ehsanaghaei/SecureBERT. Creating a new one with mean pooling.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ehsanaghaei/SecureBERT and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### embedding\n",
    "model2 = \"ehsanaghaei/SecureBERT\"\n",
    "embeddings2 = HuggingFaceEmbeddings(model_name = model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46c527a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.load_local(\"./TTPFShot-training-data-19747\", embeddings2, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d828b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc2e3bf6",
   "metadata": {},
   "source": [
    "## TTPFShot - Classification Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "23685696",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predicting single TTP label\n",
    "def predict_label(text_to_predict, train_vector_db, llm):\n",
    "    ##### Prompt 1\n",
    "    search_results = train_vector_db.similarity_search_with_score(text_to_predict, k=65)\n",
    "\n",
    "    \n",
    "    xs = [\"\\nText:\"+ doc.page_content.lower().strip()+\"\\nSimilarity:\"+ str(score) +\"\\nClassification:\"+doc.metadata['TTP_ID']+\"\\n\" for doc, score in search_results if score < 2]\n",
    "    #xs = [\"\\nText:'\"+ doc.page_content.lower().strip()+\"'\\nSimilarity:\"+ str(score) +\"\\nClassification:\"+doc.metadata['TTP_ID']+\"\\n\" for doc, score in search_results]\n",
    "    \n",
    "\n",
    "    xs = ''.join(xs)+\"\\nInputText:\"+ text_to_predict.lower().strip() +\"\\nClassification:\"\n",
    "    xs = \"\"\"You are an expert in MITRE ATT&CK TTP classification.\n",
    "    Your task is to classify the 'InputText' based on the provided examples below.\n",
    "    Each example shows a sentence, inverse similarity to InputText (the lower the better),\n",
    "    and its corresponding classification label starting with 'T'.\n",
    "    Use these examples to determine the correct classification for the given text (InputText).\n",
    "    If 'InputText' is completely not related to any of the provided examples, return class 'T0000'.\n",
    "    To determine if the 'InputText' is not related to the given examples, you can use the 'Similarity' propery of the examples.\n",
    "    Low 'Similarity' values indicate the high similarity in strings.\n",
    "    Return only the classification label starting with 'T' or 'T0000' if you found no appropriate class for 'InputText'.\\n\"\"\" + xs\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    #print(xs)\n",
    "    prompt = xs\n",
    "    result = llm.invoke(prompt)\n",
    "    predicted_label = result.content\n",
    "    return predicted_label\n",
    "\n",
    "\n",
    "### Predicting single TTP label\n",
    "def predict_label1(text_to_predict, train_vector_db, llm):\n",
    "    ##### Prompt 1\n",
    "    search_results = train_vector_db.similarity_search_with_score(text_to_predict, k=200)\n",
    "    ttp_id_counts = {}\n",
    "    \n",
    "    # Initialize a document counter\n",
    "    doc_counter = 0\n",
    "    \n",
    "    #xs = [\"\\nText:\"+ doc.page_content.lower().strip()+\"\\nSimilarity:\"+ str(score) +\"\\nClassification:\"+doc.metadata['TTP_ID']+\"\\n\" for doc, score in search_results if score < 2]\n",
    "    \n",
    "    xs = [\n",
    "        \"\\nText:\" + doc.page_content.lower().strip() +\n",
    "        \"\\nSimilarity:\" + str(score) +\n",
    "        \"\\nClassification:\" + doc.metadata['TTP_ID'] + \"\\n\"\n",
    "        for doc, score in search_results\n",
    "        if score < 2 and\n",
    "        ttp_id_counts.setdefault(doc.metadata['TTP_ID'], 0) < 5 and\n",
    "        not ttp_id_counts.update({doc.metadata['TTP_ID']: ttp_id_counts[doc.metadata['TTP_ID']] + 1})# and\n",
    "        #not (doc_counter := doc_counter + 1)\n",
    "    ]\n",
    "    \n",
    "\n",
    "    xs = ''.join(xs)+\"\\nInputText:\"+ text_to_predict.lower().strip() +\"\\nClassification:\"\n",
    "    xs = \"\"\"You are an expert in MITRE ATT&CK TTP classification.\n",
    "    Your task is to classify the 'InputText' based on the provided examples below.\n",
    "    \n",
    "    Each example includes:\n",
    "        - A sentence.\n",
    "        - An inverse similarity score with the 'InputText' (lower scores indicate higher similarity).\n",
    "        - A corresponding classification label starting with 'T'.\n",
    "    \n",
    "    Use these examples to determine the correct classification for the given text (InputText).\n",
    "    \n",
    "    If 'InputText' is completely not related to any of the provided examples, return class 'T0000'.\n",
    "    To determine if the 'InputText' is not related to the given examples, you can use the 'Similarity' propery of the examples.\n",
    "    Low 'Similarity' values indicate the high similarity in strings.\n",
    "    Return only the classification label starting with 'T' or 'T0000' if you found no appropriate class for 'InputText'.\\n\"\"\" + xs\n",
    "    \n",
    "    #####\n",
    "    #**Think through the classification process step-by-step, comparing the 'InputText' to each example, but do not share your reasoning.**\n",
    "    \n",
    "    #print(xs)\n",
    "    #print(doc_counter)\n",
    "    prompt = xs\n",
    "    result = llm.invoke(prompt)\n",
    "    predicted_label = result.content\n",
    "    return predicted_label\n",
    "\n",
    "\n",
    "\n",
    "### Predicting single TTP label\n",
    "def predict_label12(text_to_predict, train_vector_db, llm, distance=0.7):\n",
    "    ##### Prompt 1\n",
    "    search_results = train_vector_db.similarity_search_with_score(text_to_predict, k=200)\n",
    "    ttp_id_counts = {}\n",
    "    \n",
    "    # Initialize a document counter\n",
    "    doc_counter = 0\n",
    "    \n",
    "    #xs = [\"\\nText:\"+ doc.page_content.lower().strip()+\"\\nSimilarity:\"+ str(score) +\"\\nClassification:\"+doc.metadata['TTP_ID']+\"\\n\" for doc, score in search_results if score < 2]\n",
    "    \n",
    "    xs = [\n",
    "        \"\\nText:\" + doc.page_content.lower().strip() +\n",
    "        \"\\nSimilarity:\" + str(score) +\n",
    "        \"\\nClassification:\" + doc.metadata['TTP_ID'] + \"\\n\"\n",
    "        for doc, score in search_results\n",
    "        if score < distance and\n",
    "        ttp_id_counts.setdefault(doc.metadata['TTP_ID'], 0) < 5 and\n",
    "        not ttp_id_counts.update({doc.metadata['TTP_ID']: ttp_id_counts[doc.metadata['TTP_ID']] + 1})# and\n",
    "        #not (doc_counter := doc_counter + 1)\n",
    "    ]\n",
    "    \n",
    "\n",
    "    xs = ''.join(xs)+\"\\nInputText:\"+ text_to_predict.lower().strip() +\"\\nClassification:\"\n",
    "    xs = \"\"\"You are an expert in MITRE ATT&CK TTP classification.\n",
    "    Your task is to classify the 'InputText' based on the provided examples below.\n",
    "    \n",
    "    Each example includes:\n",
    "        - A sentence.\n",
    "        - An inverse similarity score with the 'InputText' (lower scores indicate higher similarity).\n",
    "        - A corresponding classification label starting with 'T'.\n",
    "    \n",
    "    Use these examples to determine the correct classification for the given text (InputText).\n",
    "    If no samples are listed, return class 'T0000'.\n",
    "    \n",
    "    If 'InputText' is completely not related to any of the provided examples, return class 'T0000'.\n",
    "    To determine if the 'InputText' is not related to the given examples, you can use the 'Similarity' propery of the examples.\n",
    "    Low 'Similarity' values indicate the high similarity in strings.\n",
    "    Return only the classification label starting with 'T' or 'T0000' if you found no appropriate class for 'InputText'.\\n\"\"\" + xs\n",
    "    \n",
    "    #####\n",
    "    #**Think through the classification process step-by-step, comparing the 'InputText' to each example, but do not share your reasoning.**\n",
    "    \n",
    "    #print(xs)\n",
    "    #print(doc_counter)\n",
    "    prompt = xs\n",
    "    result = llm.invoke(prompt)\n",
    "    predicted_label = result.content\n",
    "    return predicted_label\n",
    "\n",
    "\n",
    "\n",
    "### Enable predicting of Multiple TTP Labels\n",
    "def predict_label2(text_to_predict, train_vector_db, llm):\n",
    "    print(text_to_predict)\n",
    "    ##### Prompt 1\n",
    "    search_results = train_vector_db.similarity_search_with_score(text_to_predict, k=65)\n",
    "\n",
    "    \n",
    "    xs = [\"\\nText:\"+ doc.page_content.lower().strip()+\"\\nSimilarity:\"+ str(score) +\"\\nClassification:\"+doc.metadata['TTP_ID']+\"\\n\" for doc, score in search_results if score < 10]\n",
    "    #xs = [\"\\nText:'\"+ doc.page_content.lower().strip()+\"'\\nSimilarity:\"+ str(score) +\"\\nClassification:\"+doc.metadata['TTP_ID']+\"\\n\" for doc, score in search_results]\n",
    "    \n",
    "\n",
    "    xs = ''.join(xs)+\"\\nInputText:\"+ text_to_predict.lower().strip() +\"\\nClassification:\"\n",
    "    xs = \"\"\"You are an expert in MITRE ATT&CK TTP classification. \n",
    "    Your task is to classify the 'InputText' based on the examples provided below.\n",
    "\n",
    "        Each example includes:\n",
    "        \n",
    "        - A sentence.\n",
    "        - An inverse similarity score with the 'InputText' (lower scores indicate higher similarity).\n",
    "        - A corresponding classification label starting with 'T'.\n",
    "        \n",
    "        Use these examples to determine the correct classification label(s) for the given 'InputText'.\n",
    "        If 'InputText' is completely unrelated to any of the examples, return the classification label 'T0000'.\n",
    "        \n",
    "        To determine if 'InputText' is unrelated, refer to the 'Similarity' property of the examples.\n",
    "        Lower similarity values indicate greater similarity between strings.\n",
    "        \n",
    "        Return only the classification label(s) starting with 'T'.\n",
    "        If multiple classifications apply, list them in the format: T1111, T2222, ...\".\n",
    "        If no appropriate classification is found, return 'T0000'.\n",
    "        Do not return anything but the classification labels!\\n\"\"\" + xs\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    print(xs)\n",
    "    prompt = xs\n",
    "    result = llm.invoke(prompt)\n",
    "    predicted_label = result.content\n",
    "    return predicted_label\n",
    "\n",
    "### Zero-Shot Predictions\n",
    "def predict_label_zero(text_to_predict, llm):\n",
    "    ##### Prompt 1\n",
    "    #search_results = train_vector_db.similarity_search_with_score(text_to_predict, k=65)\n",
    "\n",
    "    \n",
    "    #xs = [\"\\nText:\"+ doc.page_content.lower().strip()+\"\\nSimilarity:\"+ str(score) +\"\\nClassification:\"+doc.metadata['TTP_ID']+\"\\n\" for doc, score in search_results if score < 2]\n",
    "    #xs = [\"\\nText:'\"+ doc.page_content.lower().strip()+\"'\\nSimilarity:\"+ str(score) +\"\\nClassification:\"+doc.metadata['TTP_ID']+\"\\n\" for doc, score in search_results]\n",
    "    \n",
    "\n",
    "    \n",
    "    xs = \"\"\"You are an expert in MITRE ATT&CK TTP classification. \n",
    "    Your task is to classify the 'InputText'.\n",
    "\n",
    "        If 'InputText' is completely unrelated to cybersecurity, return the classification label 'T0000'.\n",
    "        \n",
    "        Return only the classification label(s) starting with 'T'.\n",
    "        If no appropriate classification is found, return 'T0000'.\n",
    "        Do not return anything but the classification label!\\n\"\"\"# + xs\n",
    "    xs = ''.join(xs)+\"\\nInputText:\"+ text_to_predict.lower().strip() +\"\\nClassification:\"\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    #print(xs)\n",
    "    prompt = xs\n",
    "    result = llm.invoke(prompt)\n",
    "    predicted_label = result.content\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83ea5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "41cb537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def ttf_shot_predict(sentences, option: Literal[\"SINGLE_LABEL\", \"SINGLE_LABEL2\", \"COT\", \"MULTIPLE_LABEL\", \"ZERO_SHOT\"], llm, db, distance=0.7):\n",
    "    #print(sentences)\n",
    "    predicted_labels = []\n",
    "    # Iterating over the DataFrame row by row\n",
    "    for sentence in sentences:\n",
    "        \n",
    "        match option:\n",
    "            # single label\n",
    "            case \"SINGLE_LABEL\":\n",
    "                predicted_label = predict_label1(sentence, db, llm)\n",
    "            case \"SINGLE_LABEL2\":\n",
    "                predicted_label = predict_label12(sentence, db, llm, distance=distance)\n",
    "            # multiple label\n",
    "            case \"MULTIPLE_LABEL\":\n",
    "                predicted_label = predict_label2(sentence, db, llm)\n",
    "            # zero shot\n",
    "            case \"ZERO_SHOT\":\n",
    "                predicted_label = predict_label_zero(sentence, llm)\n",
    "            case _:\n",
    "                raise ValueError(\"Invalid option\")\n",
    "            \n",
    "        predicted_labels.append(predicted_label)\n",
    "        #predicted_labels.extend(predicted_label)\n",
    "\n",
    "    cleaned_labels = [label.replace('Classification:', '') for label in predicted_labels]\n",
    "    cleaned_labels_set = set(cleaned_labels)\n",
    "    cleaned_labels_set.discard('T0000') #  remove empty classification\n",
    "    #print(cleaned_labels_set)\n",
    "    return cleaned_labels_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "54fe8e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "\n",
    "def get_important_sentences(article):\n",
    "    # Vectorize sentences\n",
    "    sentences = sent_tokenize(article)#article.split('. ')\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    # Get sentence scores and select top sentences\n",
    "    scores = X.sum(axis=1).flatten().tolist()[0]\n",
    "    important_sentences = [sentences[i] for i in np.argsort(scores)[-5:][::-1]]\n",
    "\n",
    "    #print(\"Important Sentences:\", important_sentences)\n",
    "    return important_sentences\n",
    "\n",
    "\n",
    "def get_important_sentences2(article, n=5, score_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Extract important sentences from an article using TF-IDF scores.\n",
    "\n",
    "    Parameters:\n",
    "    - article (str): The input article text.\n",
    "    - n (int): Number of top sentences to return based on TF-IDF scores.\n",
    "    - score_threshold (float): Minimum score threshold for a sentence to be considered important.\n",
    "\n",
    "    Returns:\n",
    "    - important_sentences (list): List of important sentences.\n",
    "    \"\"\"\n",
    "    # Tokenize sentences\n",
    "    sentences = sent_tokenize(article)  # Use NLTK's sentence tokenizer\n",
    "\n",
    "    # Vectorize sentences using TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    # Calculate sentence scores by summing TF-IDF values for each sentence\n",
    "    scores = np.array(X.sum(axis=1)).flatten()  # Convert to a flat array\n",
    "\n",
    "    # Combine sentences and scores for easier filtering\n",
    "    sentence_scores = [(sentences[i], scores[i]) for i in range(len(sentences))]\n",
    "\n",
    "    # Filter sentences by threshold and sort by score (descending)\n",
    "    filtered_sentences = [s for s in sentence_scores if s[1] >= score_threshold]\n",
    "    filtered_sentences = sorted(filtered_sentences, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Select top `n` sentences\n",
    "    important_sentences = [s[0] for s in filtered_sentences[:n]]\n",
    "\n",
    "    return important_sentences\n",
    "\n",
    "\n",
    "\n",
    "def get_important_sentences3(article, n=20):\n",
    "    # Parse and summarize\n",
    "    text_to_classify = article\n",
    "    parser = PlaintextParser.from_string(text_to_classify, Tokenizer(\"english\"))\n",
    "    summarizer = TextRankSummarizer()\n",
    "    summary = summarizer(parser.document, n)  # Top 5 sentences\n",
    "\n",
    "    important_sentences = [str(sentence) for sentence in summary]\n",
    "    #print(\"Important Sentences:\", important_sentences)\n",
    "    return important_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5871a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T1082, T1049\n",
    "txt2 = \"\"\"\n",
    "Payload scans system and network for system information and network connection discovery\n",
    "\"\"\"\n",
    "### T1016 15x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44a6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8e6a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ea074228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"SINGLE_LABEL:\", ttf_shot_predict(sent_tokenize(txt2), \"SINGLE_LABEL\", llm, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b9ed468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nPayload scans system and network for system information and network connection discovery']\n",
      "SINGLE_LABEL: {'T1049'}\n"
     ]
    }
   ],
   "source": [
    "print(\"SINGLE_LABEL:\", ttf_shot_predict(get_important_sentences(txt2), \"SINGLE_LABEL\", llm, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c104f6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGLE_LABEL: {'T1082, T1049'}\n"
     ]
    }
   ],
   "source": [
    "print(\"SINGLE_LABEL:\", ttf_shot_predict([txt2], \"MULTIPLE_LABEL\", llm, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4bb395db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGLE_LABEL: {'T1049'}\n"
     ]
    }
   ],
   "source": [
    "print(\"SINGLE_LABEL:\", ttf_shot_predict(get_important_sentences(txt2), \"SINGLE_LABEL2\", llm, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "86753c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGLE_LABEL: set()\n"
     ]
    }
   ],
   "source": [
    "print(\"SINGLE_LABEL:\", ttf_shot_predict([\"hi, how are you?\"], \"SINGLE_LABEL2\", llm, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1259401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RawText</th>\n",
       "      <th>TTP</th>\n",
       "      <th>CleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.cisa.gov/news-events/cybersecurity...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...</td>\n",
       "      <td>{'T1083', 'T1071.002', 'T1055.004', 'T1657', '...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.cisa.gov/news-events/cybersecurity...</td>\n",
       "      <td>\\n\\n\\n\\nHow SVR-Attributed Actors are Adapting...</td>\n",
       "      <td>{'T1621', 'T1090.002', 'T1110', 'T1078.004', '...</td>\n",
       "      <td>\\n\\n\\n\\nHow SVR-Attributed Actors are Adapting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.cisa.gov/news-events/cybersecurity...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...</td>\n",
       "      <td>{'T1021.007', 'T1083', 'T1087.002', 'T1552.001...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.cisa.gov/news-events/cybersecurity...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...</td>\n",
       "      <td>{'TA0003', 'TA0008', 'T1083', 'T1654', 'T1078....</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.cisa.gov/news-events/cybersecurity...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...</td>\n",
       "      <td>{'TA0006', 'T1595.002', 'T1190', 'T1083', 'T15...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>https://www.cisa.gov/news-events/cybersecurity...</td>\n",
       "      <td>\\n\\n\\n\\n\\nSummary\\n\\nThis joint cybersecurity ...</td>\n",
       "      <td>{'TA0003', 'T1190', 'TA0008', 'T1110', 'T1189'...</td>\n",
       "      <td>\\n\\n\\n\\n\\nSummary\\n\\nThis joint cybersecurity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>https://www.cisa.gov/news-events/cybersecurity...</td>\n",
       "      <td>\\n\\n\\n\\n\\nSummary\\n\\nThis Alert uses the MITRE...</td>\n",
       "      <td>{'T1041', 'T1573.002', 'T1566.002', 'T1021.002...</td>\n",
       "      <td>\\n\\n\\n\\n\\nSummary\\n\\nThis Alert uses the MITRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>https://www.cisa.gov/news-events/cybersecurity...</td>\n",
       "      <td>\\n\\n\\n\\n\\nSummary\\n\\nThis Alert uses the MITRE...</td>\n",
       "      <td>{'T1041', 'T1055.012', 'T1027.002', 'T1546.008...</td>\n",
       "      <td>\\n\\n\\n\\n\\nSummary\\n\\nThis Alert uses the MITRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>https://www.cisa.gov/news-events/cybersecurity...</td>\n",
       "      <td>\\n\\n\\n\\n\\nSummary\\n\\nThis Alert uses the MITRE...</td>\n",
       "      <td>{'T1083', 'T1016', 'T1036.005', 'T1105', 'T108...</td>\n",
       "      <td>\\n\\n\\n\\n\\nSummary\\n\\nThis Alert uses the MITRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>https://www.cisa.gov/news-events/cybersecurity...</td>\n",
       "      <td>\\n\\n\\n\\n\\nSummary\\n\\nThis advisory uses the MI...</td>\n",
       "      <td>{'T1498', 'TA0010', 'T1499', 'T1253', 'T1190',...</td>\n",
       "      <td>\\n\\n\\n\\n\\nSummary\\n\\nThis advisory uses the MI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Unnamed: 0  \\\n",
       "0   https://www.cisa.gov/news-events/cybersecurity...   \n",
       "1   https://www.cisa.gov/news-events/cybersecurity...   \n",
       "2   https://www.cisa.gov/news-events/cybersecurity...   \n",
       "3   https://www.cisa.gov/news-events/cybersecurity...   \n",
       "4   https://www.cisa.gov/news-events/cybersecurity...   \n",
       "..                                                ...   \n",
       "72  https://www.cisa.gov/news-events/cybersecurity...   \n",
       "73  https://www.cisa.gov/news-events/cybersecurity...   \n",
       "74  https://www.cisa.gov/news-events/cybersecurity...   \n",
       "75  https://www.cisa.gov/news-events/cybersecurity...   \n",
       "76  https://www.cisa.gov/news-events/cybersecurity...   \n",
       "\n",
       "                                              RawText  \\\n",
       "0   \\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...   \n",
       "1   \\n\\n\\n\\nHow SVR-Attributed Actors are Adapting...   \n",
       "2   \\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...   \n",
       "3   \\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...   \n",
       "4   \\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...   \n",
       "..                                                ...   \n",
       "72  \\n\\n\\n\\n\\nSummary\\n\\nThis joint cybersecurity ...   \n",
       "73  \\n\\n\\n\\n\\nSummary\\n\\nThis Alert uses the MITRE...   \n",
       "74  \\n\\n\\n\\n\\nSummary\\n\\nThis Alert uses the MITRE...   \n",
       "75  \\n\\n\\n\\n\\nSummary\\n\\nThis Alert uses the MITRE...   \n",
       "76  \\n\\n\\n\\n\\nSummary\\n\\nThis advisory uses the MI...   \n",
       "\n",
       "                                                  TTP  \\\n",
       "0   {'T1083', 'T1071.002', 'T1055.004', 'T1657', '...   \n",
       "1   {'T1621', 'T1090.002', 'T1110', 'T1078.004', '...   \n",
       "2   {'T1021.007', 'T1083', 'T1087.002', 'T1552.001...   \n",
       "3   {'TA0003', 'TA0008', 'T1083', 'T1654', 'T1078....   \n",
       "4   {'TA0006', 'T1595.002', 'T1190', 'T1083', 'T15...   \n",
       "..                                                ...   \n",
       "72  {'TA0003', 'T1190', 'TA0008', 'T1110', 'T1189'...   \n",
       "73  {'T1041', 'T1573.002', 'T1566.002', 'T1021.002...   \n",
       "74  {'T1041', 'T1055.012', 'T1027.002', 'T1546.008...   \n",
       "75  {'T1083', 'T1016', 'T1036.005', 'T1105', 'T108...   \n",
       "76  {'T1498', 'TA0010', 'T1499', 'T1253', 'T1190',...   \n",
       "\n",
       "                                            CleanText  \n",
       "0   \\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...  \n",
       "1   \\n\\n\\n\\nHow SVR-Attributed Actors are Adapting...  \n",
       "2   \\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...  \n",
       "3   \\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...  \n",
       "4   \\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...  \n",
       "..                                                ...  \n",
       "72  \\n\\n\\n\\n\\nSummary\\n\\nThis joint cybersecurity ...  \n",
       "73  \\n\\n\\n\\n\\nSummary\\n\\nThis Alert uses the MITRE...  \n",
       "74  \\n\\n\\n\\n\\nSummary\\n\\nThis Alert uses the MITRE...  \n",
       "75  \\n\\n\\n\\n\\nSummary\\n\\nThis Alert uses the MITRE...  \n",
       "76  \\n\\n\\n\\n\\nSummary\\n\\nThis advisory uses the MI...  \n",
       "\n",
       "[77 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reports = pd.read_csv(\"../TTP-crawler/CISA-crawl-rt-ttp-ct.csv\")\n",
    "df_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f41ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reports = df_reports.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0d3f47b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RawText</th>\n",
       "      <th>TTP</th>\n",
       "      <th>CleanText</th>\n",
       "      <th>ttpfshot_sl</th>\n",
       "      <th>ttpfshot_ml2</th>\n",
       "      <th>ttpfshot_sli</th>\n",
       "      <th>ttpfshot_sli2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.cisa.gov/news-events/cybersecurity...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...</td>\n",
       "      <td>{'T1083', 'T1071.002', 'T1055.004', 'T1657', '...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...</td>\n",
       "      <td>{T1567.002, T1102.002, T1219, T1550.002, T1548...</td>\n",
       "      <td>{T1490}</td>\n",
       "      <td>{T1567.002, T1548.003, T1219, T1550.002, T1105...</td>\n",
       "      <td>{T1567.002, T1548.003, T1219, T1105, T1076, T1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.cisa.gov/news-events/cybersecurity...</td>\n",
       "      <td>\\n\\n\\n\\nHow SVR-Attributed Actors are Adapting...</td>\n",
       "      <td>{'T1621', 'T1090.002', 'T1110', 'T1078.004', '...</td>\n",
       "      <td>\\n\\n\\n\\nHow SVR-Attributed Actors are Adapting...</td>\n",
       "      <td>{T1090.001, T1591.004, T1070, T1586.003, T1136...</td>\n",
       "      <td>{T1490}</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Unnamed: 0  \\\n",
       "0  https://www.cisa.gov/news-events/cybersecurity...   \n",
       "1  https://www.cisa.gov/news-events/cybersecurity...   \n",
       "\n",
       "                                             RawText  \\\n",
       "0  \\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...   \n",
       "1  \\n\\n\\n\\nHow SVR-Attributed Actors are Adapting...   \n",
       "\n",
       "                                                 TTP  \\\n",
       "0  {'T1083', 'T1071.002', 'T1055.004', 'T1657', '...   \n",
       "1  {'T1621', 'T1090.002', 'T1110', 'T1078.004', '...   \n",
       "\n",
       "                                           CleanText  \\\n",
       "0  \\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...   \n",
       "1  \\n\\n\\n\\nHow SVR-Attributed Actors are Adapting...   \n",
       "\n",
       "                                         ttpfshot_sl ttpfshot_ml2  \\\n",
       "0  {T1567.002, T1102.002, T1219, T1550.002, T1548...      {T1490}   \n",
       "1  {T1090.001, T1591.004, T1070, T1586.003, T1136...      {T1490}   \n",
       "\n",
       "                                        ttpfshot_sli  \\\n",
       "0  {T1567.002, T1548.003, T1219, T1550.002, T1105...   \n",
       "1                                                      \n",
       "\n",
       "                                       ttpfshot_sli2  \n",
       "0  {T1567.002, T1548.003, T1219, T1105, T1076, T1...  \n",
       "1                                                     "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cab14e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DSC Benchmarking - TTPXHunter vs. TTPFShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8331406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text nr:  0\n",
      "ttpfshot_sl done in: 3.0470416227976482 minutes\n",
      "ttpfshot_sl: {'T1567.002', 'T1102.002', 'T1219', 'T1550.002', 'T1548.003', 'T1105', 'T1489', 'T1076', 'T1083', 'T1070.004', 'T1027', 'T1110.003', 'T1562.011', 'T1140', 'T1562.004', 'T1201', 'T1562.001', 'T1110.001', 'T1598.004', 'T1552.001', 'T1490', 'T1553', 'T1537', 'T1021.001', 'T1070.001', 'T1588.001', 'T1560', 'T1599', 'T1486', 'T1053.005', 'T1094', 'T1059.003', 'T1553.006', 'T1059', 'T1016', 'T1555.003', 'T1556.002', 'T1586', 'T1657', 'T1547.001', 'T1003.005', 'T1087', 'T1556.004', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1218.005', 'T1136.001', 'T1597.001', 'T1021', 'T1555.005'}\n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 2.0276062448819476 minutes\n",
      "ttpfshot_sl: {'T1090.001', 'T1591.004', 'T1548.003', 'T1070', 'T1136.003', 'T1586.003', 'T1098.005', 'T1110.003', 'T1621', 'T1550.001', 'T1201', 'T1588.002', 'T1071.001', 'T1078.003', 'T1665', 'T1190', 'T1528', 'T1599', 'T1108', 'T1589.002', 'T1029', 'T1111', 'T1078', 'T1090.002', 'T1036', 'T1098.001', 'T1195.002', 'T1078.004'}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#df_reports[\"ttpxhunter\"] = \"\"\n",
    "df_reports[\"ttpfshot_sl\"] = \"\"\n",
    "#df_reports[\"ttpfshot_ml\"] = \"\"\n",
    "#df_reports[\"ttpfshot_zs\"] = \"\"\n",
    "\n",
    "for index, row in df_reports.iterrows():\n",
    "    #print(f\"Index: {index}\")\n",
    "    print(\"text nr: \", index)\n",
    "    \n",
    "    text_to_classify = row[\"CleanText\"]\n",
    " \n",
    "    \n",
    "    start_time = time.time()\n",
    "    ttpfshot_sl = ttf_shot_predict(sent_tokenize(text_to_classify), \"SINGLE_LABEL2\", llm, db)\n",
    "    elapsed_time = (time.time() - start_time)/60\n",
    "    print(f\"ttpfshot_sl done in: {elapsed_time} minutes\")\n",
    "    \n",
    "    '''\n",
    "    start_time = time.time()\n",
    "    ttpfshot_ml = ttf_shot_predict(sent_tokenize(text_to_classify), \"MULTIPLE_LABEL\", llm, db3)\n",
    "    elapsed_time = (time.time() - start_time)/60\n",
    "    print(f\"ttpfshot_ml done in: {elapsed_time} minutes\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ttpfshot_zs = ttf_shot_predict(sent_tokenize(text_to_classify), \"ZERO_SHOT\", llm, db3)\n",
    "    elapsed_time = (time.time() - start_time)/60\n",
    "    print(f\"ttpfshot_zs done in: {elapsed_time} minutes\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ttps, ttp_names = extract_ttp_from_sentences(sent_tokenize(text_to_classify), th, label_dict, ttpid2name)#(text_to_classify, th, label_dict, ttpid2name)\n",
    "    elapsed_time = (time.time() - start_time)/60\n",
    "    print(f\"ttpxhunter done in: {elapsed_time} minutes\")\n",
    "    '''\n",
    "    ### save results to the reports dataframe\n",
    "    #df_reports.at[index, 'ttpxhunter'] = ttps\n",
    "    df_reports.at[index, 'ttpfshot_sl'] = ttpfshot_sl\n",
    "    #df_reports.at[index, 'ttpfshot_ml'] = ttpfshot_ml\n",
    "    #df_reports.at[index, 'ttpfshot_zs'] = ttpfshot_zs\n",
    "   \n",
    "    \n",
    "    #print(\"ttpxhunter:\", ttps)\n",
    "    #print(\"ttpxhunter:\", ttps)\n",
    "    print(\"ttpfshot_sl:\", ttpfshot_sl)\n",
    "    #print(\"ttpfshot_ml:\", ttpfshot_ml)\n",
    "    #print(\"ttpZshot_zs:\", ttpfshot_zs)\n",
    "    \n",
    "    #TTPFShot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f325ade0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3210eb20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ce27899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, f1_score, precision_score, recall_score, jaccard_score\n",
    "\n",
    "def calculate_metrics2(df, y_true_col, y_pred_col, key):\n",
    "    # Convert columns to lists of sets\n",
    "    y_true = df[y_true_col].apply(lambda x: eval(x) if isinstance(x, str) else x).tolist()\n",
    "    y_pred = df[y_pred_col].tolist()\n",
    "\n",
    "    # Define all unique TTPs across the entire dataset\n",
    "    all_ttps = set.union(*y_true, *y_pred)\n",
    "\n",
    "    # Use MultiLabelBinarizer to transform labels\n",
    "    mlb = MultiLabelBinarizer(classes=list(all_ttps))\n",
    "    y_true_bin = mlb.fit_transform(y_true)\n",
    "    y_pred_bin = mlb.transform(y_pred)\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        \"subset_accuracy\": accuracy_score(y_true_bin, y_pred_bin),\n",
    "        \"hamming_accuracy\": 1 - hamming_loss(y_true_bin, y_pred_bin),\n",
    "        \"f1_micro\": f1_score(y_true_bin, y_pred_bin, average='micro'),\n",
    "        \"f1_macro\": f1_score(y_true_bin, y_pred_bin, average='macro'),\n",
    "        \"f1_weighted\": f1_score(y_true_bin, y_pred_bin, average='weighted'),\n",
    "        \"precision_micro\": precision_score(y_true_bin, y_pred_bin, average='micro'),\n",
    "        \"precision_macro\": precision_score(y_true_bin, y_pred_bin, average='macro'),\n",
    "        \"recall_micro\": recall_score(y_true_bin, y_pred_bin, average='micro'),\n",
    "        \"recall_macro\": recall_score(y_true_bin, y_pred_bin, average='macro'),\n",
    "        \"jaccard_micro\": jaccard_score(y_true_bin, y_pred_bin, average='micro'),\n",
    "        \"jaccard_macro\": jaccard_score(y_true_bin, y_pred_bin, average='macro')\n",
    "    }\n",
    "    \n",
    "    # Return the metrics dictionary for the specified key\n",
    "    return {key: metrics}\n",
    "\n",
    "\n",
    "def calculate_single_label_metrics2(df, y_true_col, y_pred_col, key):\n",
    "    # Convert columns to lists (no need for sets or multi-label encoding)\n",
    "    y_true = df[y_true_col].tolist()\n",
    "    y_pred = df[y_pred_col].tolist()\n",
    "\n",
    "    # Calculate metrics for single-label classification\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"hamming_accuracy\": 1 - hamming_loss(y_true, y_pred),\n",
    "        \"f1_micro\": f1_score(y_true, y_pred, average='micro'),\n",
    "        \"f1_macro\": f1_score(y_true, y_pred, average='macro'),\n",
    "        \"f1_weighted\": f1_score(y_true, y_pred, average='weighted'),\n",
    "        \"precision_micro\": precision_score(y_true, y_pred, average='micro'),\n",
    "        \"precision_macro\": precision_score(y_true, y_pred, average='macro'),\n",
    "        \"recall_micro\": recall_score(y_true, y_pred, average='micro'),\n",
    "        \"recall_macro\": recall_score(y_true, y_pred, average='macro'),\n",
    "        \"jaccard_micro\": jaccard_score(y_true, y_pred, average='micro'),\n",
    "        \"jaccard_macro\": jaccard_score(y_true, y_pred, average='macro')\n",
    "    }\n",
    "    \n",
    "    # Return the metrics dictionary for the specified key\n",
    "    return {key: metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e96e6d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subset_accuracy</th>\n",
       "      <th>hamming_accuracy</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>jaccard_micro</th>\n",
       "      <th>jaccard_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ttpfshot_sl</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.187135</td>\n",
       "      <td>0.418301</td>\n",
       "      <td>0.236559</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.184211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
       "ttpfshot_sl              0.0          0.561404  0.305556  0.187135   \n",
       "\n",
       "             f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
       "ttpfshot_sl     0.418301         0.236559         0.184211      0.431373   \n",
       "\n",
       "             recall_macro  jaccard_micro  jaccard_macro  \n",
       "ttpfshot_sl      0.192982       0.180328       0.184211  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_scores = {\n",
    "    #\"ttpxhunter\" : calculate_metrics2(df_reports, 'TTP', 'ttpxhunter', 'ttpxhunter'),\n",
    "    \"ttpfshot_sl\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_sl', 'ttpfshot_sl'),\n",
    "    #\"ttpfshot_ml\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_ml', 'ttpfshot_ml'),\n",
    "    #\"ttpfshot_zs\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_zs', 'ttpfshot_zs')\n",
    "}\n",
    "\n",
    "#scores_df = pd.DataFrame(all_scores)#.transpose()\n",
    "\n",
    "#print(scores_df)\n",
    "\n",
    "flattened_data = {outer_key: inner_dict[outer_key] for outer_key, inner_dict in all_scores.items()}\n",
    "\n",
    "# Create DataFrame\n",
    "scores_df = pd.DataFrame(flattened_data).transpose()\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7fb28",
   "metadata": {},
   "source": [
    "### SINGLE_LABEL 2 - trehsold 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2ef9479a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subset_accuracy</th>\n",
       "      <th>hamming_accuracy</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>jaccard_micro</th>\n",
       "      <th>jaccard_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ttpfshot_sl</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.567308</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.201923</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.201923</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.201923</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.201923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
       "ttpfshot_sl              0.0          0.567308  0.318182  0.201923   \n",
       "\n",
       "             f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
       "ttpfshot_sl     0.411765         0.259259         0.201923      0.411765   \n",
       "\n",
       "             recall_macro  jaccard_micro  jaccard_macro  \n",
       "ttpfshot_sl      0.201923       0.189189       0.201923  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_scores = {\n",
    "    #\"ttpxhunter\" : calculate_metrics2(df_reports, 'TTP', 'ttpxhunter', 'ttpxhunter'),\n",
    "    \"ttpfshot_sl\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_sl', 'ttpfshot_sl'),\n",
    "    #\"ttpfshot_ml\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_ml', 'ttpfshot_ml'),\n",
    "    #\"ttpfshot_zs\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_zs', 'ttpfshot_zs')\n",
    "}\n",
    "\n",
    "#scores_df = pd.DataFrame(all_scores)#.transpose()\n",
    "\n",
    "#print(scores_df)\n",
    "\n",
    "flattened_data = {outer_key: inner_dict[outer_key] for outer_key, inner_dict in all_scores.items()}\n",
    "\n",
    "# Create DataFrame\n",
    "scores_df = pd.DataFrame(flattened_data).transpose()\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374ee1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488123e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f97b3017",
   "metadata": {},
   "source": [
    "### Important sentence Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5833fe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text nr:  0\n",
      "ttpfshot_sl done in: 1.4069068074226379 minutes\n",
      "ttpfshot_sli: {'T1548.003', 'T1219', 'T1550.002', 'T1105', 'T1083', 'T1076', 'T1021.002', 'T1027', 'T1140', 'T1562.004', 'T1201', 'T1562.001', 'T1110.001', 'T1518.001', 'T1490', 'T1588.001', 'T1486', 'T1053.005', 'T1094', 'T1059.003', 'T1059', 'T1657', 'T1547.001', 'T1003.005', 'T1556.004', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1597.001'}\n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 1.3267831524213156 minutes\n",
      "ttpfshot_sli: {'T1591.004', 'T1070', 'T1548.003', 'T1586.003', 'T1136.003', 'T1583.003', 'T1098.005', 'T1580', 'T1110.003', 'T1594', 'T1556.006', 'T1597.001', 'T1621', 'T1550', 'T1588.002', 'T1071.001', 'T1078.003', 'T1665', 'T1190', 'T1528', 'T1599', 'T1649', 'T1108', 'T1589.002', 'T1583', 'T1527', 'T1029', 'T1111', 'T1078', 'T1090.002', 'T1036', 'T1098.001', 'T1195.002', 'T1078.004'}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#df_reports[\"ttpxhunter\"] = \"\"\n",
    "df_reports[\"ttpfshot_sli\"] = \"\"\n",
    "#df_reports[\"ttpfshot_ml2\"] = \"\"\n",
    "#df_reports[\"ttpfshot_ml\"] = \"\"\n",
    "#df_reports[\"ttpfshot_zs\"] = \"\"\n",
    "\n",
    "for index, row in df_reports.iterrows():\n",
    "    #print(f\"Index: {index}\")\n",
    "    print(\"text nr: \", index)\n",
    "    \n",
    "    text_to_classify = row[\"CleanText\"]\n",
    " \n",
    "   \n",
    "    start_time = time.time()\n",
    "    ttpfshot_sli = ttf_shot_predict(get_important_sentences2(text_to_classify, n=60), \"SINGLE_LABEL\", llm, db)\n",
    "    elapsed_time = (time.time() - start_time)/60\n",
    "    print(f\"ttpfshot_sl done in: {elapsed_time} minutes\")\n",
    "    '''\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ttpfshot_ml2 = ttf_shot_predict([text_to_classify], \"MULTIPLE_LABEL\", llm, db)\n",
    "    elapsed_time = (time.time() - start_time)/60\n",
    "    print(f\"ttpfshot_ml done in: {elapsed_time} minutes\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ttpfshot_zs = ttf_shot_predict(sent_tokenize(text_to_classify), \"ZERO_SHOT\", llm, db3)\n",
    "    elapsed_time = (time.time() - start_time)/60\n",
    "    print(f\"ttpfshot_zs done in: {elapsed_time} minutes\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ttps, ttp_names = extract_ttp_from_sentences(sent_tokenize(text_to_classify), th, label_dict, ttpid2name)#(text_to_classify, th, label_dict, ttpid2name)\n",
    "    elapsed_time = (time.time() - start_time)/60\n",
    "    print(f\"ttpxhunter done in: {elapsed_time} minutes\")\n",
    "    '''\n",
    "    ### save results to the reports dataframe\n",
    "    #df_reports.at[index, 'ttpxhunter'] = ttps\n",
    "    #df_reports.at[index, 'ttpfshot_sl'] = ttpfshot_sl\n",
    "    df_reports.at[index, 'ttpfshot_sli'] = ttpfshot_sli\n",
    "    #df_reports.at[index, 'ttpfshot_zs'] = ttpfshot_zs\n",
    "   \n",
    "    \n",
    "    #print(\"ttpxhunter:\", ttps)\n",
    "    #print(\"ttpxhunter:\", ttps)\n",
    "    #print(\"ttpfshot_sl:\", ttpfshot_sl)\n",
    "    print(\"ttpfshot_sli:\", ttpfshot_sli)\n",
    "    #print(\"ttpZshot_zs:\", ttpfshot_zs)\n",
    "    \n",
    "    #TTPFShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "040399d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subset_accuracy</th>\n",
       "      <th>hamming_accuracy</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>jaccard_micro</th>\n",
       "      <th>jaccard_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ttpfshot_sli</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.557895</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.168421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
       "ttpfshot_sli              0.0          0.557895  0.275862  0.168421   \n",
       "\n",
       "              f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
       "ttpfshot_sli     0.313725         0.246154         0.168421      0.313725   \n",
       "\n",
       "              recall_macro  jaccard_micro  jaccard_macro  \n",
       "ttpfshot_sli      0.168421           0.16       0.168421  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_scores = {\n",
    "    #\"ttpxhunter\" : calculate_metrics2(df_reports, 'TTP', 'ttpxhunter', 'ttpxhunter'),\n",
    "    \"ttpfshot_sli\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_sli', 'ttpfshot_sli'),\n",
    "    #\"ttpfshot_ml\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_ml', 'ttpfshot_ml'),\n",
    "    #\"ttpfshot_zs\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_zs', 'ttpfshot_zs')\n",
    "}\n",
    "\n",
    "#scores_df = pd.DataFrame(all_scores)#.transpose()\n",
    "\n",
    "#print(scores_df)\n",
    "\n",
    "flattened_data = {outer_key: inner_dict[outer_key] for outer_key, inner_dict in all_scores.items()}\n",
    "\n",
    "# Create DataFrame\n",
    "scores_df = pd.DataFrame(flattened_data).transpose()\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0967cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d035642b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text nr:  0\n",
      "Important Sentences: ['CISA: Known Exploited Vulnerabilities Catalog\\nCISA, MITRE: Best Practices for MITRE ATT&CK Mapping\\nCISA: Decider Tool\\nCISA: Cross-Sector Cybersecurity Performance Goals\\nCISA: Secure by Design\\nCISA: Implementing Phishing-Resistant MFA\\nCISA: Guide to Securing Remote Access Software\\n\\nREFERENCES,1, Privacy Affairs: â€œMoralâ€ 8Base Ransomware Targets 2 New Victims,2, VMware: 8base ransomware: A Heavy Hitting Player,3, Infosecurity Magazine: Phobos Ransomware Family Expands With New FAUST Variant,4, The Record: Hospitals offline across Romania following ransomware attack on IT platform,5, Comparitech: What is Phobos Ransomware & How to Protect Against It?,6, Cisco Talos: Understanding the Phobos affiliate structure and activity,7, Cisco Talos: A deep dive into Phobos ransomware, recently deployed by 8Base group,8, Malwarebytes Labs: A deep dive into Phobos ransomware,9, Any Run: Smokeloader,10, Malpedia: Smokeloader,11, Truesec:\\xa0A case of the FAUST Ransomware,12,\\xa0VirusTotal: Phobos Domain #1,13, VirusTotal: Phobos executable: Ahpdate.exe,14, VirusTotal: Phobos GUI extension: ELF File,15, VirusTotal: Phobos IP address: 185.202.0,.,111,16, VirusTotal: Phobos GUI extension: Binary File,17,\\xa0Cisco Talos GitHub: IOCs/2023/11/deep-dive-into-phobos-ransomware.txt at main\\nREPORTING\\nThe FBI is seeking any information that can be shared, to include boundary logs showing communication to and from foreign IP addresses, a sample ransom-note, communications with Phobos actors, Bitcoin wallet information, decryptor files, and/or a benign sample of an encrypted file.', 'The Windows command shell enables threat actors to control various aspects of a system, with multiple permission levels required for different subsets of commands,.,8,\\nSmokeloader Deployment\\nPhobos operations feature a standard three phase process to decrypt a payload that allows the threat actors to deploy additional destructive malware.,9,\\nFor the first phase, Smokeloader manipulates either VirtualAlloc or VirtualProtect API functionsâ€”which opens an entry point, enabling code to be injected into running processes and allowing the malware to evade network defense tools,.', 'These tools are all widely accessible and easy to use in various operating environments, making it (and associated variants) a popular choice for many threat actors.,3,4,\\nReconnaissance and Initial Access\\nPhobos actors typically gain initial access to vulnerable networks by leveraging phishing campaigns, to drop hidden payloads or using internet protocol (IP) scanning tools, such as Angry IP Scanner, to search for vulnerable Remote Desktop Protocol (RDP) ports, or by leveraging RDP on Microsoft Windows environments.,5,6,\\nOnce they discover an exposed RDP service, the actors use open source brute force tools to gain access,.', 'In addition, the authoring authorities of this CSA recommend network defenders apply the following mitigations to limit potential adversarial use of common system and network discovery techniques, and to reduce the impact and risk of compromise by ransomware or data extortion actors:\\n\\nImplement a recovery plan to maintain and retain multiple copies of sensitive or proprietary data and servers in a physically separate, segmented, and secure location (i.e., hard drive, storage device, or the cloud).', 'Phobos has also been observed using Windows Startup folders and Run Registry Keys such as C:/Users\\\\Admin\\\\AppData\\\\Local\\\\directory, to maintain persistence within compromised environments.,5,\\nAdditionally, Phobos actors have been observed using built-in Windows API functions, to steal tokens, bypass access controls, and create new processes to escalate privileges by leveraging the SeDebugPrivilege process,.']\n",
      "text nr:  1\n",
      "Important Sentences: ['\\n\\n\\n\\nHow SVR-Attributed Actors are Adapting to the Move of Government and Corporations to Cloud Infrastructure\\nOVERVIEW\\nThis advisory details recent tactics, techniques, and procedures (TTPs) of the group commonly known as APT29, also known as Midnight Blizzard, the Dukes, or Cozy Bear.', 'CONCLUSION\\nThe SVR is a sophisticated actor capable of carrying out a global supply chain compromise such as the 2020 SolarWinds, however the guidance in this advisory shows that a strong baseline of cyber security fundamentals can help defend from such actors.', 'The US National Security Agency (NSA), the US Cybersecurity and Infrastructure Security Agency (CISA), the US Cyber National Mission Force (CNMF), the Federal Bureau of Investigation (FBI), Australian Signals Directorateâ€™s Australian Cyber Security Centre (ASDâ€™s ACSC), the Canadian Centre for Cyber Security (CCCS), and New Zealand Government Communications Security Bureau (GCSB) agree with this attribution and the details provided in this advisory.', 'This reduces the effectiveness of network defenses that use IP addresses as indicators of compromise, and so it is important to consider a variety of information sources such as application and host-based logging for detecting suspicious activity.', 'MITIGATION AND DETECTION\\nA number of mitigations will be useful in defending against the activity described in this advisory:\\xa0\\n\\nUse multi-factor authentication (/2-factor authentication/two-step verification) to reduce the impact of password compromises.']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for index, row in df_reports.iterrows():\n",
    "    #print(f\"Index: {index}\")\n",
    "    print(\"text nr: \", index)\n",
    "    \n",
    "    text_to_classify = row[\"CleanText\"]\n",
    "    # Vectorize sentences\n",
    "    sentences = sent_tokenize(text_to_classify)#article.split('. ')\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    # Get sentence scores and select top sentences\n",
    "    scores = X.sum(axis=1).flatten().tolist()[0]\n",
    "    important_sentences = [sentences[i] for i in np.argsort(scores)[-5:][::-1]]\n",
    "\n",
    "    print(\"Important Sentences:\", important_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e9b70c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sumy\n",
      "  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/lib/python3/dist-packages (from sumy) (0.6.2)\n",
      "Collecting breadability>=0.1.20 (from sumy)\n",
      "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.7.0 in /home/hamzicd/.local/lib/python3.12/site-packages (from sumy) (2.32.0)\n",
      "Requirement already satisfied: pycountry>=18.2.23 in /home/hamzicd/.local/lib/python3.12/site-packages (from sumy) (24.6.1)\n",
      "Requirement already satisfied: nltk>=3.0.2 in /home/hamzicd/.local/lib/python3.12/site-packages (from sumy) (3.9.1)\n",
      "Requirement already satisfied: chardet in /usr/lib/python3/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
      "Requirement already satisfied: lxml>=2.0 in /usr/lib/python3/dist-packages (from breadability>=0.1.20->sumy) (5.2.1)\n",
      "Requirement already satisfied: click in /home/hamzicd/.local/lib/python3.12/site-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/hamzicd/.local/lib/python3.12/site-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/hamzicd/.local/lib/python3.12/site-packages (from nltk>=3.0.2->sumy) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /home/hamzicd/.local/lib/python3.12/site-packages (from nltk>=3.0.2->sumy) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hamzicd/.local/lib/python3.12/site-packages (from requests>=2.7.0->sumy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.7.0->sumy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.7.0->sumy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.7.0->sumy) (2023.11.17)\n",
      "Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: breadability\n",
      "  Building wheel for breadability (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21693 sha256=0ef6fa5bf3eda91ad511583c9f2c9d70cd9ba2fd84718d66e6d83d38b9c91b06\n",
      "  Stored in directory: /home/hamzicd/.cache/pip/wheels/32/99/64/59305409cacd03aa03e7bddf31a9db34b1fa7033bd41972662\n",
      "Successfully built breadability\n",
      "Installing collected packages: breadability, sumy\n",
      "Successfully installed breadability-0.1.20 sumy-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sumy --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e76bcd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text nr:  0\n",
      "Important Sentences: ['The Federal Bureau of Investigation (FBI), the Cybersecurity and Infrastructure Security Agency (CISA), and the Multi-State Information Sharing and Analysis Center (MS-ISAC) are releasing this joint CSA, to disseminate known TTPs and IOCs associated with the Phobos ransomware variants observed as recently as February 2024, according to open source reporting.', 'These incidents targeted municipal and county governments, emergency services, education, public healthcare, and other critical infrastructure entities to successfully ransom several million U.S. dollars.,1,2, The FBI, CISA, and the MS-ISAC encourage organizations to implement the recommendations in the Mitigations section of this CSA to reduce the likelihood and impact of Phobos ransomware and other ransomware incidents.', 'See the MITRE ATT&CK Tactics and Techniques section for a table of the threat actorsâ€™ activity mapped to MITRE ATT&CKÂ® tactics and techniques.', 'For assistance with mapping malicious cyber activity to the MITRE ATT&CK framework, see CISA and MITRE ATT&CKâ€™s Best Practices for MITRE ATT&CK Mapping and CISAâ€™s Decider Tool.', 'These tools are all widely accessible and easy to use in various operating environments, making it (and associated variants) a popular choice for many threat actors.,3,4, Reconnaissance and Initial Access Phobos actors typically gain initial access to vulnerable networks by leveraging phishing campaigns, to drop hidden payloads or using internet protocol (IP) scanning tools, such as Angry IP Scanner, to search for vulnerable Remote Desktop Protocol (RDP) ports, or by leveraging RDP on Microsoft Windows environments.,5,6, Once they discover an exposed RDP service, the actors use open source brute force tools to gain access,.', 'If Phobos actors gain successful RDP authentication, in the targeted environment, they perform open source research to create a victim profile and connect the targeted IP addresses to their associated companies,.', 'After SmokeLoaderâ€™s hidden payload is downloaded onto the victimâ€™s system, threat actors use the malwareâ€™s functionality to download the Phobos payload and exfiltrate data from the compromised system.', 'The Windows command shell enables threat actors to control various aspects of a system, with multiple permission levels required for different subsets of commands,.,8, Smokeloader Deployment Phobos operations feature a standard three phase process to decrypt a payload that allows the threat actors to deploy additional destructive malware.,9, For the first phase, Smokeloader manipulates either VirtualAlloc or VirtualProtect API functionsâ€”which opens an entry point, enabling code to be injected into running processes and allowing the malware to evade network defense tools,.', 'In the second phase, a stealth process is used to obfuscate command and control (C2) activity by producing requests to legitimate websites,.,10, Within this phase, the shellcode also sends a call from the entry point to a memory container, and prepares a portable executable for deployment in the final stage,.', 'Phobos has also been observed using Windows Startup folders and Run Registry Keys such as C:/Users\\\\Admin\\\\AppData\\\\Local\\\\directory, to maintain persistence within compromised environments.,5, Additionally, Phobos actors have been observed using built-in Windows API functions, to steal tokens, bypass access controls, and create new processes to escalate privileges by leveraging the SeDebugPrivilege process,.', 'Disclaimer: Organizations are encouraged to investigate the use of the file hashes in Tables 8 and 9 for related signs of compromise prior to performing remediation actions.', 'The FBI, CISA, and MS-ISAC recommend that software manufacturers incorporate secure by design and default principles and tactics into their software development practices limiting the impact of ransomware techniques, thus, strengthening the secure posture for their customers.', 'CISA and NIST based the CPGs on existing cybersecurity frameworks and guidance to protect against the most common and impactful threats, tactics, techniques, and procedures.', 'In addition, the authoring authorities of this CSA recommend network defenders apply the following mitigations to limit potential adversarial use of common system and network discovery techniques, and to reduce the impact and risk of compromise by ransomware or data extortion actors:', 'Implement a recovery plan to maintain and retain multiple copies of sensitive or proprietary data and servers in a physically separate, segmented, and secure location (i.e., hard drive, storage device, or the cloud).', \"In addition to applying mitigations, the FBI, CISA, and MS-ISAC recommend exercising, testing, and validating your organization's security program against the threat behaviors mapped to the MITRE ATT&CK for Enterprise framework in this advisory.\", 'The FBI, CISA, and MS-ISAC recommend continually testing your security program, at scale, in a production environment to ensure optimal performance against the MITRE ATT&CK techniques identified in this advisory.', 'REFERENCES,1, Privacy Affairs: â€œMoralâ€ 8Base Ransomware Targets 2 New Victims,2, VMware: 8base ransomware: A Heavy Hitting Player,3, Infosecurity Magazine: Phobos Ransomware Family Expands With New FAUST Variant,4, The Record: Hospitals offline across Romania following ransomware attack on IT platform,5, Comparitech: What is Phobos Ransomware & How to Protect Against It?,6, Cisco Talos: Understanding the Phobos affiliate structure and activity,7, Cisco Talos: A deep dive into Phobos ransomware, recently deployed by 8Base group,8, Malwarebytes Labs: A deep dive into Phobos ransomware,9, Any Run: Smokeloader,10, Malpedia: Smokeloader,11, Truesec:\\xa0A case of the FAUST Ransomware,12,\\xa0VirusTotal: Phobos Domain #1,13, VirusTotal: Phobos executable: Ahpdate.exe,14, VirusTotal: Phobos GUI extension: ELF File,15, VirusTotal: Phobos IP address: 185.202.0,.,111,16, VirusTotal: Phobos GUI extension: Binary File,17,\\xa0Cisco Talos GitHub: IOCs/2023/11/deep-dive-into-phobos-ransomware.txt at main', 'The FBI is seeking any information that can be shared, to include boundary logs showing communication to and from foreign IP addresses, a sample ransom-note, communications with Phobos actors, Bitcoin wallet information, decryptor files, and/or a benign sample of an encrypted file.', 'Regardless of whether you or your organization have decided to pay the ransom, the FBI and CISA urge you to promptly report ransomware incidents to the FBI Internet Crime Complaint Center (IC3), a local FBI Field Office, or to CISA at report@cisa.gov or by calling 1-844-Say-CISA (1-844-729-2472).']\n",
      "text nr:  1\n",
      "Important Sentences: ['How SVR-Attributed Actors are Adapting to the Move of Government and Corporations to Cloud Infrastructure', 'The UK National Cyber Security Centre (NCSC) and international partners assess that APT29 is a cyber espionage group, almost certainly part of the SVR, an element of the Russian intelligence services.', 'The US National Security Agency (NSA), the US Cybersecurity and Infrastructure Security Agency (CISA), the US Cyber National Mission Force (CNMF), the Federal Bureau of Investigation (FBI), Australian Signals Directorateâ€™s Australian Cyber Security Centre (ASDâ€™s ACSC), the Canadian Centre for Cyber Security (CCCS), and New Zealand Government Communications Security Bureau (GCSB) agree with this attribution and the details provided in this advisory.', 'This advisory provides an overview of TTPs deployed by the actor to gain initial access into the cloud environment and includes advice to detect and mitigate this activity.', 'EVOLVING\\xa0TTPs As organizations continue to modernize their systems and move to cloud-based infrastructure, the SVR has adapted to these changes in the operating environment.', 'They have to move beyond their traditional means of initial access, such as exploiting software vulnerabilities in an on-premises network, and instead target the cloud services themselves.', 'To access the majority of the victimsâ€™ cloud hosted network, actors must first successfully authenticate to the cloud provider.', 'The NCSC and partners have observed SVR actors using tokens to access their victimsâ€™ accounts, without needing a password,.', 'The default validity time of system-issued tokens varies dependent on the system; however, cloud platforms should allow administrators to adjust the validity time as appropriate for their users.', 'SVR actors have also then bypassed MFA through a technique known as â€œMFA bombingâ€\\xa0or â€œMFA fatigue,â€ in which the actors repeatedly push MFA requests to a victimâ€™s device until the victim accepts the notification,.', 'Once an actor has bypassed these systems to gain access to the cloud environment, SVR actors have been observed registering their own device as a new device on the cloud tenant,.', 'By configuring the network with device enrollment policies, there have been instances where these measures have defended against SVR actors and denied them access to the cloud tenant.', 'This reduces the effectiveness of network defenses that use IP addresses as indicators of compromise, and so it is important to consider a variety of information sources such as application and host-based logging for detecting suspicious activity.', 'The SVR is a sophisticated actor capable of carrying out a global supply chain compromise such as the 2020 SolarWinds, however the guidance in this advisory shows that a strong baseline of cyber security fundamentals can help defend from such actors.', 'For organizations that have moved to cloud infrastructure, a first line of defense against an actor such as SVR should be to protect against SVRâ€™s TTPs for initial access.', 'Some of the TTPs listed in this report, such as residential proxies and exploitation of system accounts, are similar to those reported as recently as January 2024 by Microsoft.', 'User and system accounts should be disabled when no longer required with a â€œjoiners, movers, and leaversâ€ process in place and regular reviews to identify and disable inactive/dormant accounts.', 'System and service accounts should implement the principle of least privilege, providing tightly scoped access to resources required for the service to function.', 'Session lifetimes should be kept as short as practical to reduce the window of opportunity for an adversary to use stolen session tokens.', 'Any NCSC findings and recommendations made have not been provided with the intention of avoiding all risks and following the recommendations will not remove all such risk.']\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "\n",
    "# Parse and summarize\n",
    "\n",
    "for index, row in df_reports.iterrows():\n",
    "    #print(f\"Index: {index}\")\n",
    "    print(\"text nr: \", index)\n",
    "    \n",
    "    text_to_classify = row[\"CleanText\"]\n",
    "    parser = PlaintextParser.from_string(text_to_classify, Tokenizer(\"english\"))\n",
    "    summarizer = TextRankSummarizer()\n",
    "    summary = summarizer(parser.document, 20)  # Top 5 sentences\n",
    "\n",
    "    print(\"Important Sentences:\", [str(sentence) for sentence in summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb35333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5346e718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee5b64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e468456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c893c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a214fefa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cf49d43",
   "metadata": {},
   "source": [
    "### Varying Article's number of important sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7a985de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RawText</th>\n",
       "      <th>TTP</th>\n",
       "      <th>CleanText</th>\n",
       "      <th>ttpfshot_sl</th>\n",
       "      <th>ttpfshot_ml2</th>\n",
       "      <th>ttpfshot_sli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.cisa.gov/news-events/cybersecurity...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...</td>\n",
       "      <td>{'T1083', 'T1071.002', 'T1055.004', 'T1657', '...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...</td>\n",
       "      <td>{T1567.002, T1102.002, T1219, T1550.002, T1548...</td>\n",
       "      <td>{T1490}</td>\n",
       "      <td>{T1548.003, T1219, T1550.002, T1105, T1083, T1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.cisa.gov/news-events/cybersecurity...</td>\n",
       "      <td>\\n\\n\\n\\nHow SVR-Attributed Actors are Adapting...</td>\n",
       "      <td>{'T1621', 'T1090.002', 'T1110', 'T1078.004', '...</td>\n",
       "      <td>\\n\\n\\n\\nHow SVR-Attributed Actors are Adapting...</td>\n",
       "      <td>{T1090.001, T1591.004, T1070, T1586.003, T1136...</td>\n",
       "      <td>{T1490}</td>\n",
       "      <td>{T1591.004, T1070, T1548.003, T1586.003, T1136...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Unnamed: 0  \\\n",
       "0  https://www.cisa.gov/news-events/cybersecurity...   \n",
       "1  https://www.cisa.gov/news-events/cybersecurity...   \n",
       "\n",
       "                                             RawText  \\\n",
       "0  \\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...   \n",
       "1  \\n\\n\\n\\nHow SVR-Attributed Actors are Adapting...   \n",
       "\n",
       "                                                 TTP  \\\n",
       "0  {'T1083', 'T1071.002', 'T1055.004', 'T1657', '...   \n",
       "1  {'T1621', 'T1090.002', 'T1110', 'T1078.004', '...   \n",
       "\n",
       "                                           CleanText  \\\n",
       "0  \\n\\n\\n\\n\\n\\n\\nActions to take today to mitigat...   \n",
       "1  \\n\\n\\n\\nHow SVR-Attributed Actors are Adapting...   \n",
       "\n",
       "                                         ttpfshot_sl ttpfshot_ml2  \\\n",
       "0  {T1567.002, T1102.002, T1219, T1550.002, T1548...      {T1490}   \n",
       "1  {T1090.001, T1591.004, T1070, T1586.003, T1136...      {T1490}   \n",
       "\n",
       "                                        ttpfshot_sli  \n",
       "0  {T1548.003, T1219, T1550.002, T1105, T1083, T1...  \n",
       "1  {T1591.004, T1070, T1548.003, T1586.003, T1136...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a69b4ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text nr:  0\n",
      "ttpfshot_sl done in: 0.2899808605511983 minutes\n",
      "ttpfshot_sl done in: 0.43698720932006835 minutes\n",
      "ttpfshot_sli: {'T1140', 'T1219', 'T1547.001', 'T1486', 'T1094', 'T1055.001', 'T1110.001'}\n",
      "ttpfshot_sli2: {'T1486', 'T1094', 'T1055.001', 'T1110.001'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sli               0.0          0.528302  0.137931  0.075472   \n",
      "ttpfshot_sli2              0.0          0.500000  0.036364  0.018868   \n",
      "\n",
      "               f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sli      0.078431         0.571429         0.075472      0.078431   \n",
      "ttpfshot_sli2     0.019608         0.250000         0.018868      0.019608   \n",
      "\n",
      "               recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sli       0.075472       0.074074       0.075472  \n",
      "ttpfshot_sli2      0.018868       0.018519       0.018868  \n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 0.3100603381792704 minutes\n",
      "ttpfshot_sl done in: 0.21674156586329144 minutes\n",
      "ttpfshot_sli: {'T1556.006', 'T1190', 'T1599', 'T1071.001', 'T1589.002', 'T1078.004'}\n",
      "ttpfshot_sli2: {'T1621', 'T1599', 'T1548.005', 'T1583.003', 'T1098.005', 'T1580', 'T1078.004'}\n",
      "               subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sli               0.0          0.534483  0.156250  0.086207   \n",
      "ttpfshot_sli2              0.0          0.526316  0.129032  0.070175   \n",
      "\n",
      "               f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sli      0.098039         0.384615         0.086207      0.098039   \n",
      "ttpfshot_sli2     0.078431         0.363636         0.070175      0.078431   \n",
      "\n",
      "               recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sli       0.086207       0.084746       0.086207  \n",
      "ttpfshot_sli2      0.070175       0.068966       0.070175  \n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 0.5507293621699015 minutes\n",
      "ttpfshot_sl done in: 0.5495056867599487 minutes\n",
      "ttpfshot_sli: {'T1140', 'T1219', 'T1588.001', 'T1547.001', 'T1486', 'T1094', 'T1591', 'T1055.001', 'T1110.001'}\n",
      "ttpfshot_sli2: {'T1005', 'T1547.001', 'T1105', 'T1486', 'T1094', 'T1591', 'T1055.001', 'T1110.001', 'T1490'}\n",
      "               subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sli               0.0          0.527273  0.133333  0.072727   \n",
      "ttpfshot_sli2              0.0          0.527273  0.133333  0.072727   \n",
      "\n",
      "               f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sli      0.078431         0.444444         0.072727      0.078431   \n",
      "ttpfshot_sli2     0.078431         0.444444         0.072727      0.078431   \n",
      "\n",
      "               recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sli       0.072727       0.071429       0.072727  \n",
      "ttpfshot_sli2      0.072727       0.071429       0.072727  \n",
      "text nr:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 0.5436028599739074 minutes\n",
      "ttpfshot_sl done in: 0.47669459581375123 minutes\n",
      "ttpfshot_sli: {'T1556.006', 'T1665', 'T1591.004', 'T1190', 'T1586', 'T1599', 'T1111', 'T1071.001', 'T1586.003', 'T1090.002', 'T1098.005', 'T1531', 'T1589.002', 'T1583'}\n",
      "ttpfshot_sli2: {'T1621', 'T1190', 'T1528', 'T1599', 'T1586.003', 'T1548.005', 'T1583.003', 'T1098.001', 'T1098.005', 'T1580', 'T1078.003', 'T1583', 'T1078.004'}\n",
      "               subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sli               0.0          0.537313  0.162162  0.089552   \n",
      "ttpfshot_sli2              0.0          0.554688  0.219178  0.125000   \n",
      "\n",
      "               f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sli      0.117647         0.260870         0.089552      0.117647   \n",
      "ttpfshot_sli2     0.156863         0.363636         0.125000      0.156863   \n",
      "\n",
      "               recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sli       0.089552       0.088235       0.089552  \n",
      "ttpfshot_sli2      0.125000       0.123077       0.125000  \n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 0.6607790311177572 minutes\n",
      "ttpfshot_sl done in: 0.7723033587137859 minutes\n",
      "ttpfshot_sli: {'T1140', 'T1219', 'T1562.004', 'T1588.001', 'T1657', 'T1547.001', 'T1111', 'T1486', 'T1201', 'T1094', 'T1591', 'T1055.001', 'T1027', 'T1110.001', 'T1561'}\n",
      "ttpfshot_sli2: {'T1219', 'T1586', 'T1547.001', 'T1105', 'T1486', 'T1094', 'T1562.009', 'T1591', 'T1055.001', 'T1069.002', 'T1110.001', 'T1597.001', 'T1490'}\n",
      "               subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sli               0.0          0.542373  0.181818  0.101695   \n",
      "ttpfshot_sli2              0.0          0.534483  0.156250  0.086207   \n",
      "\n",
      "               f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sli      0.117647         0.400000         0.101695      0.117647   \n",
      "ttpfshot_sli2     0.098039         0.384615         0.086207      0.098039   \n",
      "\n",
      "               recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sli       0.101695       0.100000       0.101695  \n",
      "ttpfshot_sli2      0.086207       0.084746       0.086207  \n",
      "text nr:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 1.0492721875508626 minutes\n",
      "ttpfshot_sl done in: 0.698396913210551 minutes\n",
      "ttpfshot_sli: {'T1591.004', 'T1070', 'T1586.003', 'T1583.003', 'T1098.005', 'T1580', 'T1110.003', 'T1556.006', 'T1588.002', 'T1071.001', 'T1078.003', 'T1665', 'T1190', 'T1588.001', 'T1599', 'T1589.002', 'T1583', 'T1078', 'T1098.001', 'T1078.004'}\n",
      "ttpfshot_sli2: {'T1621', 'T1190', 'T1528', 'T1599', 'T1110', 'T1588.002', 'T1078', 'T1586.003', 'T1548.005', 'T1583.003', 'T1098.001', 'T1098.005', 'T1580', 'T1078.003', 'T1078.004'}\n",
      "               subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sli               0.0          0.527027  0.186047  0.108108   \n",
      "ttpfshot_sli2              0.0          0.553030  0.253165  0.146465   \n",
      "\n",
      "               f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sli      0.156863         0.228571         0.108108      0.156863   \n",
      "ttpfshot_sli2     0.202614         0.357143         0.151515      0.196078   \n",
      "\n",
      "               recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sli       0.108108       0.102564       0.108108  \n",
      "ttpfshot_sli2      0.143939       0.144928       0.143939  \n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 1.1317535996437074 minutes\n",
      "ttpfshot_sl done in: 1.0441596666971842 minutes\n",
      "ttpfshot_sli: {'T1219', 'T1021.002', 'T1027', 'T1140', 'T1562.004', 'T1201', 'T1110.001', 'T1518.001', 'T1588.001', 'T1486', 'T1094', 'T1059.003', 'T1059', 'T1657', 'T1547.001', 'T1003.005', 'T1556.004', 'T1591', 'T1055.001', 'T1048.003', 'T1597.001'}\n",
      "ttpfshot_sli2: {'T1070', 'T1219', 'T1547.001', 'T1105', 'T1486', 'T1111', 'T1094', 'T1562.009', 'T1591', 'T1055.001', 'T1069.002', 'T1110.001', 'T1048.003', 'T1597.001', 'T1490'}\n",
      "               subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sli               0.0          0.555556  0.222222  0.126984   \n",
      "ttpfshot_sli2              0.0          0.533333  0.151515  0.083333   \n",
      "\n",
      "               f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sli      0.156863         0.380952         0.126984      0.156863   \n",
      "ttpfshot_sli2     0.098039         0.333333         0.083333      0.098039   \n",
      "\n",
      "               recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sli       0.126984       0.125000       0.126984  \n",
      "ttpfshot_sli2      0.083333       0.081967       0.083333  \n",
      "text nr:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 0.8081622759501139 minutes\n",
      "ttpfshot_sl done in: 0.9157024304072062 minutes\n",
      "ttpfshot_sli: {'T1591.004', 'T1070', 'T1548.003', 'T1586.003', 'T1136.003', 'T1583.003', 'T1098.005', 'T1531', 'T1580', 'T1110.003', 'T1556.006', 'T1621', 'T1550.001', 'T1588.002', 'T1071.001', 'T1078.003', 'T1591.002', 'T1665', 'T1190', 'T1528', 'T1588.001', 'T1599', 'T1589.002', 'T1078', 'T1090.002', 'T1078.004'}\n",
      "ttpfshot_sli2: {'T1548.003', 'T1070', 'T1586.003', 'T1583.003', 'T1098.005', 'T1580', 'T1621', 'T1550.001', 'T1110', 'T1588.002', 'T1562.001', 'T1078.003', 'T1190', 'T1528', 'T1588.001', 'T1599', 'T1589.002', 'T1078', 'T1078.004'}\n",
      "               subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sli               0.0          0.555556  0.265306  0.160494   \n",
      "ttpfshot_sli2              0.0          0.542254  0.235294  0.136150   \n",
      "\n",
      "               f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sli      0.254902         0.276596         0.160494      0.254902   \n",
      "ttpfshot_sli2     0.202614         0.294118         0.140845      0.196078   \n",
      "\n",
      "               recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sli       0.160494       0.152941       0.160494  \n",
      "ttpfshot_sli2      0.133803       0.133333       0.133803  \n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 1.5441052556037902 minutes\n",
      "ttpfshot_sl done in: 1.2504356106122334 minutes\n",
      "ttpfshot_sli: {'T1219', 'T1105', 'T1021.002', 'T1027', 'T1140', 'T1562.004', 'T1201', 'T1555.004', 'T1110.001', 'T1518.001', 'T1490', 'T1588.001', 'T1486', 'T1053.005', 'T1094', 'T1059.003', 'T1059', 'T1657', 'T1547.001', 'T1111', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1597.001'}\n",
      "ttpfshot_sli2: {'T1567.002', 'T1070', 'T1219', 'T1105', 'T1027', 'T1140', 'T1110.001', 'T1490', 'T1486', 'T1053.005', 'T1094', 'T1556.002', 'T1586', 'T1657', 'T1547.001', 'T1111', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1597.001'}\n",
      "               subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sli               0.0          0.559701  0.233766  0.134328   \n",
      "ttpfshot_sli2              0.0          0.554688  0.219178  0.125000   \n",
      "\n",
      "               f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sli      0.176471         0.346154         0.134328      0.176471   \n",
      "ttpfshot_sli2     0.156863         0.363636         0.125000      0.156863   \n",
      "\n",
      "               recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sli       0.134328       0.132353       0.134328  \n",
      "ttpfshot_sli2      0.125000       0.123077       0.125000  \n",
      "text nr:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 0.9182106097539265 minutes\n",
      "ttpfshot_sl done in: 1.1207191626230875 minutes\n",
      "ttpfshot_sli: {'T1591.004', 'T1070', 'T1548.003', 'T1586.003', 'T1136.003', 'T1583.003', 'T1098.005', 'T1531', 'T1580', 'T1110.003', 'T1594', 'T1556.006', 'T1621', 'T1550', 'T1550.001', 'T1588.002', 'T1071.001', 'T1078.003', 'T1665', 'T1190', 'T1528', 'T1599', 'T1589.002', 'T1583', 'T1111', 'T1078', 'T1090.002', 'T1036', 'T1078.004'}\n",
      "ttpfshot_sli2: {'T1090.001', 'T1591.004', 'T1548.003', 'T1070', 'T1586.003', 'T1583.003', 'T1098.005', 'T1580', 'T1110.003', 'T1621', 'T1550.001', 'T1110', 'T1588.002', 'T1071.001', 'T1078.003', 'T1665', 'T1190', 'T1528', 'T1588.001', 'T1599', 'T1108', 'T1566.002', 'T1589.002', 'T1078', 'T1078.004'}\n",
      "               subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sli               0.0          0.556818  0.264151  0.159091   \n",
      "ttpfshot_sli2              0.0          0.555556  0.265306  0.156379   \n",
      "\n",
      "               f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sli      0.274510         0.254545         0.159091      0.274510   \n",
      "ttpfshot_sli2     0.261438         0.276596         0.160494      0.254902   \n",
      "\n",
      "               recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sli       0.159091       0.152174       0.159091  \n",
      "ttpfshot_sli2      0.154321       0.152941       0.154321  \n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 1.868380347887675 minutes\n",
      "ttpfshot_sl done in: 1.3387726346651714 minutes\n",
      "ttpfshot_sli: {'T1548.003', 'T1219', 'T1550.002', 'T1105', 'T1083', 'T1076', 'T1021.002', 'T1027', 'T1140', 'T1562.004', 'T1201', 'T1562.001', 'T1110.001', 'T1591.001', 'T1518.001', 'T1490', 'T1588.001', 'T1486', 'T1053.005', 'T1094', 'T1059.003', 'T1059', 'T1657', 'T1547.001', 'T1111', 'T1003.005', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1597.001'}\n",
      "ttpfshot_sli2: {'T1567.002', 'T1548.003', 'T1219', 'T1105', 'T1021.002', 'T1027', 'T1140', 'T1110.001', 'T1490', 'T1486', 'T1053.005', 'T1094', 'T1556.002', 'T1586', 'T1657', 'T1547.001', 'T1585.002', 'T1111', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1218.005', 'T1597.001', 'T1598.003'}\n",
      "               subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sli               0.0          0.570423  0.265060  0.154930   \n",
      "ttpfshot_sli2              0.0          0.559701  0.233766  0.134328   \n",
      "\n",
      "               f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sli      0.215686         0.343750         0.154930      0.215686   \n",
      "ttpfshot_sli2     0.176471         0.346154         0.134328      0.176471   \n",
      "\n",
      "               recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sli       0.154930       0.152778       0.154930  \n",
      "ttpfshot_sli2      0.134328       0.132353       0.134328  \n",
      "text nr:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 1.2041556398073832 minutes\n",
      "ttpfshot_sl done in: 1.8261729637781778 minutes\n",
      "ttpfshot_sli: {'T1591.004', 'T1070', 'T1548.003', 'T1586.003', 'T1136.003', 'T1583.003', 'T1098.005', 'T1580', 'T1110.003', 'T1556.006', 'T1597.001', 'T1621', 'T1550', 'T1550.001', 'T1588.002', 'T1071.001', 'T1078.003', 'T1591.002', 'T1665', 'T1190', 'T1528', 'T1599', 'T1649', 'T1108', 'T1589.002', 'T1583', 'T1029', 'T1111', 'T1078', 'T1090.002', 'T1036', 'T1098.001', 'T1195.002', 'T1078.004'}\n",
      "ttpfshot_sli2: {'T1090.001', 'T1591.004', 'T1548.003', 'T1070', 'T1136.003', 'T1586.003', 'T1583.003', 'T1098.005', 'T1580', 'T1110.003', 'T1526', 'T1621', 'T1550', 'T1588.002', 'T1071.001', 'T1078.003', 'T1591.002', 'T1665', 'T1190', 'T1528', 'T1588.001', 'T1599', 'T1649', 'T1108', 'T1566.002', 'T1589.002', 'T1078', 'T1036', 'T1098.001', 'T1078.004'}\n",
      "               subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sli               0.0          0.552632  0.273504  0.168421   \n",
      "ttpfshot_sli2              0.0          0.550000  0.242991  0.144444   \n",
      "\n",
      "               f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sli      0.313725         0.242424         0.168421      0.313725   \n",
      "ttpfshot_sli2     0.254902         0.232143         0.144444      0.254902   \n",
      "\n",
      "               recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sli       0.168421       0.158416       0.168421  \n",
      "ttpfshot_sli2      0.144444       0.138298       0.144444  \n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 2.0096505165100096 minutes\n",
      "ttpfshot_sl done in: 3.3639552275339764 minutes\n",
      "ttpfshot_sli: {'T1567.002', 'T1548.003', 'T1219', 'T1550.002', 'T1105', 'T1083', 'T1076', 'T1021.002', 'T1027', 'T1562.011', 'T1140', 'T1562.004', 'T1218', 'T1201', 'T1555.004', 'T1562.001', 'T1110.001', 'T1591.001', 'T1518.001', 'T1598.004', 'T1490', 'T1588.001', 'T1486', 'T1053.005', 'T1094', 'T1059.003', 'T1059', 'T1016', 'T1555.003', 'T1556.002', 'T1657', 'T1547.001', 'T1111', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1485', 'T1597.001'}\n",
      "ttpfshot_sli2: {'T1567.002', 'T1548.003', 'T1219', 'T1105', 'T1076', 'T1021.002', 'T1027', 'T1140', 'T1562.004', 'T1218', 'T1555.004', 'T1562.001', 'T1110.001', 'T1518.001', 'T1490', 'T1021.001', 'T1082', 'T1599', 'T1486', 'T1053.005', 'T1094', 'T1553.006', 'T1059', 'T1556.002', 'T1586', 'T1657', 'T1547.001', 'T1585.002', 'T1111', 'T1078', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1218.005', 'T1485', 'T1597.001'}\n",
      "               subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sli               0.0          0.570513  0.263736  0.153846   \n",
      "ttpfshot_sli2              0.0          0.572368  0.269663  0.157895   \n",
      "\n",
      "               f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sli      0.235294         0.300000         0.153846      0.235294   \n",
      "ttpfshot_sli2     0.235294         0.315789         0.157895      0.235294   \n",
      "\n",
      "               recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sli       0.153846       0.151899       0.153846  \n",
      "ttpfshot_sli2      0.157895       0.155844       0.157895  \n",
      "text nr:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m text_to_classify \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCleanText\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     20\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 21\u001b[0m ttpfshot_sli \u001b[38;5;241m=\u001b[39m \u001b[43mttf_shot_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_important_sentences2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_to_classify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_top_sent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSINGLE_LABEL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mttpfshot_sl done in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[89], line 12\u001b[0m, in \u001b[0;36mttf_shot_predict\u001b[0;34m(sentences, option, llm, db)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mmatch\u001b[39;00m option:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# single label\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSINGLE_LABEL\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m         predicted_label \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_label1\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# multiple label\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMULTIPLE_LABEL\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Cell \u001b[0;32mIn[58], line 76\u001b[0m, in \u001b[0;36mpredict_label1\u001b[0;34m(text_to_predict, train_vector_db, llm)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#####\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m#**Think through the classification process step-by-step, comparing the 'InputText' to each example, but do not share your reasoning.**\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m#print(xs)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m#print(doc_counter)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m prompt \u001b[38;5;241m=\u001b[39m xs\n\u001b[0;32m---> 76\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted_label\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    285\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    647\u001b[0m ]\n\u001b[1;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 633\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m         )\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:689\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 689\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/openai/resources/chat/completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/openai/_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1277\u001b[0m     )\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/openai/_base_client.py:991\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    988\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 991\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    997\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.12/ssl.py:1233\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1230\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1232\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.12/ssl.py:1106\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "for n_top_sent in [10,20,30,40,50,60,80,100]:\n",
    "\n",
    "    #df_reports[\"ttpxhunter\"] = \"\"\n",
    "    df_reports[\"ttpfshot_sli\"] = \"\"\n",
    "    df_reports[\"ttpfshot_sli2\"] = \"\"\n",
    "    #df_reports[\"ttpfshot_ml2\"] = \"\"\n",
    "    #df_reports[\"ttpfshot_ml\"] = \"\"\n",
    "    #df_reports[\"ttpfshot_zs\"] = \"\"\n",
    "\n",
    "    for index, row in df_reports.iterrows():\n",
    "        #print(f\"Index: {index}\")\n",
    "        print(\"text nr: \", index)\n",
    "\n",
    "        text_to_classify = row[\"CleanText\"]\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "        ttpfshot_sli = ttf_shot_predict(get_important_sentences2(text_to_classify, n=n_top_sent), \"SINGLE_LABEL\", llm, db)\n",
    "        elapsed_time = (time.time() - start_time)/60\n",
    "        print(f\"ttpfshot_sl done in: {elapsed_time} minutes\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        ttpfshot_sli2 = ttf_shot_predict(get_important_sentences3(text_to_classify, n=n_top_sent), \"SINGLE_LABEL\", llm, db)\n",
    "        elapsed_time = (time.time() - start_time)/60\n",
    "        print(f\"ttpfshot_sl done in: {elapsed_time} minutes\")\n",
    "        '''\n",
    "\n",
    "        start_time = time.time()\n",
    "        ttpfshot_ml2 = ttf_shot_predict([text_to_classify], \"MULTIPLE_LABEL\", llm, db)\n",
    "        elapsed_time = (time.time() - start_time)/60\n",
    "        print(f\"ttpfshot_ml done in: {elapsed_time} minutes\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        ttpfshot_zs = ttf_shot_predict(sent_tokenize(text_to_classify), \"ZERO_SHOT\", llm, db3)\n",
    "        elapsed_time = (time.time() - start_time)/60\n",
    "        print(f\"ttpfshot_zs done in: {elapsed_time} minutes\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        ttps, ttp_names = extract_ttp_from_sentences(sent_tokenize(text_to_classify), th, label_dict, ttpid2name)#(text_to_classify, th, label_dict, ttpid2name)\n",
    "        elapsed_time = (time.time() - start_time)/60\n",
    "        print(f\"ttpxhunter done in: {elapsed_time} minutes\")\n",
    "        '''\n",
    "        ### save results to the reports dataframe\n",
    "        #df_reports.at[index, 'ttpxhunter'] = ttps\n",
    "        #df_reports.at[index, 'ttpfshot_sl'] = ttpfshot_sl\n",
    "        df_reports.at[index, 'ttpfshot_sli'] = ttpfshot_sli\n",
    "        df_reports.at[index, 'ttpfshot_sli2'] = ttpfshot_sli2\n",
    "        #df_reports.at[index, 'ttpfshot_zs'] = ttpfshot_zs\n",
    "\n",
    "\n",
    "        #print(\"ttpxhunter:\", ttps)\n",
    "        #print(\"ttpxhunter:\", ttps)\n",
    "        #print(\"ttpfshot_sl:\", ttpfshot_sl)\n",
    "        print(\"ttpfshot_sli:\", ttpfshot_sli)\n",
    "        print(\"ttpfshot_sli2:\", ttpfshot_sli2)\n",
    "        #print(\"ttpZshot_zs:\", ttpfshot_zs)\n",
    "\n",
    "        #Evaluate\n",
    "        all_scores = {\n",
    "            #\"ttpxhunter\" : calculate_metrics2(df_reports, 'TTP', 'ttpxhunter', 'ttpxhunter'),\n",
    "            \"ttpfshot_sli\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_sli', 'ttpfshot_sli'),\n",
    "            \"ttpfshot_sli2\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_sli2', 'ttpfshot_sli2'),\n",
    "            #\"ttpfshot_ml\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_ml', 'ttpfshot_ml'),\n",
    "            #\"ttpfshot_zs\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_zs', 'ttpfshot_zs')\n",
    "        }\n",
    "\n",
    "        #scores_df = pd.DataFrame(all_scores)#.transpose()\n",
    "\n",
    "        #print(scores_df)\n",
    "\n",
    "        flattened_data = {outer_key: inner_dict[outer_key] for outer_key, inner_dict in all_scores.items()}\n",
    "\n",
    "        # Create DataFrame\n",
    "        scores_df = pd.DataFrame(flattened_data).transpose()\n",
    "        print(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55109dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d440c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10d83ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc178b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c919c0f4",
   "metadata": {},
   "source": [
    "### Simulate different distance tresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e9961178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_distance: 0.2\n",
      "text nr:  0\n",
      "ttpfshot_sl done in: 2.610564192136129 minutes\n",
      "ttpfshot_sl: {'T1488', 'T1213', 'T1552', 'T1219', 'T1210', 'T1070', 'T1102', 'T1589', 'T1027', 'T1543', 'T1562', 'T1542', 'T1550', 'T1203', 'T1201', 'T1110', 'T1212', 'T1049', 'T1587', 'T1490', 'T1553', 'T1547', 'T1567', 'T1190', 'T1560', 'T1486', 'T1595', 'T1583', 'T1059', 'T1003', 'T1204', 'T1566', 'T1569', 'T1078', 'T1087', 'T1485', 'T1040', 'T1592', 'T1021'}\n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 1.2081881364186604 minutes\n",
      "ttpfshot_sl: {'T1589', 'T1531', 'T1090', 'T1562', 'T1071', 'T1200', 'T1550', 'T1556', 'T1110', 'T1193', 'T1190', 'T1583', 'T1195', 'T1529', 'T1111', 'T1233', 'T1078', 'T1087', 'T1036'}\n",
      "             subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sl              0.0               0.5  0.146789    0.0681   \n",
      "\n",
      "             f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sl     0.143791         0.137931         0.064516      0.156863   \n",
      "\n",
      "             recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sl      0.075269       0.079208       0.064516  \n",
      "min_distance: 0.3\n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 2.3340789755185445 minutes\n",
      "ttpfshot_sl: {'T1567.002', 'T1213', 'T1219', 'T1210', 'T1105', 'T1102', 'T1489', 'T1083', 'T1076', 'T1589', 'T1070.004', 'T1027', 'T1110.003', 'T1562', 'T1071', 'T1140', 'T1201', 'T1110', 'T1212', 'T1562.001', 'T1049', 'T1587', 'T1490', 'T1480.001', 'T1553', 'T1190', 'T1588.001', 'T1560', 'T1486', 'T1053.005', 'T1595', 'T1094', 'T1135', 'T1059.003', 'T1003.001', 'T1657', 'T1547.001', 'T1566', 'T1569', 'T1078', 'T1087', 'T1562.009', 'T1485', 'T1055.001', 'T1048.003', 'T1069.002', 'T1592', 'T1218.005', 'T1136.001', 'T1040', 'T1021'}\n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 1.320796791712443 minutes\n",
      "ttpfshot_sl: {'T1070', 'T1098.005', 'T1531', 'T1110.003', 'T1584.008', 'T1090', 'T1071', 'T1200', 'T1621', 'T1550', 'T1556', 'T1110', 'T1078.003', 'T1587', 'T1193', 'T1665', 'T1528', 'T1190', 'T1589.002', 'T1195', 'T1029', 'T1555.003', 'T1078', 'T1087', 'T1036', 'T1578.005', 'T1133'}\n",
      "             subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sl              0.0             0.555  0.310078  0.186667   \n",
      "\n",
      "             f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sl     0.385621          0.25641            0.185      0.392157   \n",
      "\n",
      "             recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sl          0.19       0.183486          0.185  \n",
      "min_distance: 0.4\n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 2.4592469930648804 minutes\n",
      "ttpfshot_sl: {'T1567.002', 'T1548.003', 'T1219', 'T1550.002', 'T1105', 'T1489', 'T1076', 'T1083', 'T1021.002', 'T1070.004', 'T1027', 'T1555', 'T1562.004', 'T1201', 'T1588.002', 'T1110', 'T1555.004', 'T1588', 'T1562.001', 'T1110.001', 'T1548.002', 'T1518.001', 'T1587', 'T1598.004', 'T1490', 'T1070.001', 'T1560', 'T1599', 'T1486', 'T1595', 'T1094', 'T1059.003', 'T1566.002', 'T1553.006', 'T1059', 'T1016', 'T1555.003', 'T1657', 'T1547.001', 'T1216', 'T1071.003', 'T1562.009', 'T1591', 'T1218.005', 'T1048.003', 'T1069.002', 'T1556.', 'T1021', 'T1555.005'}\n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 1.307725767294566 minutes\n",
      "ttpfshot_sl: {'T1591.004', 'T1210', 'T1583.003', 'T1098.005', 'T1556.009', 'T1110.003', 'T1090', 'T1594', 'T1562', 'T1200', 'T1621', 'T1588.002', 'T1071.001', 'T1078.003', 'T1193', 'T1665', 'T1190', 'T1528', 'T1108', 'T1589.002', 'T1029', 'T1189', 'T1111', 'T1078', 'T1090.002', 'T1036', 'T1098.001', 'T1195.002', 'T1535', 'T1078.004'}\n",
      "             subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sl              0.0          0.586538  0.338462  0.205128   \n",
      "\n",
      "             f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sl     0.431373         0.278481         0.206731      0.431373   \n",
      "\n",
      "             recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sl      0.206731       0.203704       0.201923  \n",
      "min_distance: 0.5\n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 2.7725648204485576 minutes\n",
      "ttpfshot_sl: {'T1567.002', 'T1102.002', 'T1219', 'T1550.002', 'T1548.003', 'T1105', 'T1489', 'T1076', 'T1083', 'T1070.004', 'T1027', 'T1561', 'T1110.003', 'T1140', 'T1562.004', 'T1201', 'T1110', 'T1110.004', 'T1597.002', 'T1588', 'T1562.001', 'T1110.001', 'T1548.002', 'T1518.001', 'T1598.004', 'T1587', 'T1490', 'T1021.001', 'T1537', 'T1070.001', 'T1588.001', 'T1560', 'T1599', 'T1486', 'T1094', 'T1059.003', 'T1553.006', 'T1059', 'T1016', 'T1555.003', 'T1556.002', 'T1657', 'T1547.001', 'T1111', 'T1003.005', 'T1087', 'T1556.004', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1218.005', 'T1136.001', 'T1597.001', 'T1485', 'T1562.002', 'T1555.005'}\n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 1.3962675213813782 minutes\n",
      "ttpfshot_sl: {'T1090.001', 'T1591.004', 'T1548.003', 'T1070', 'T1136.003', 'T1498', 'T1098.005', 'T1531', 'T1110.003', 'T1621', 'T1550.001', 'T1201', 'T1588.002', 'T1071.001', 'T1078.003', 'T1193', 'T1665', 'T1190', 'T1528', 'T1078.002', 'T1599', 'T1649', 'T1108', 'T1589.002', 'T1583', 'T1029', 'T1586', 'T1111', 'T1078', 'T1036', 'T1098.001', 'T1195.002', 'T1078.004'}\n",
      "             subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sl              0.0          0.557522  0.295775  0.182891   \n",
      "\n",
      "             f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sl     0.418301         0.230769         0.185841      0.411765   \n",
      "\n",
      "             recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sl      0.181416       0.173554       0.181416  \n",
      "min_distance: 0.7\n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 2.9277570645014444 minutes\n",
      "ttpfshot_sl: {'T1567.002', 'T1560.001', 'T1102.002', 'T1219', 'T1550.002', 'T1548.003', 'T1105', 'T1076', 'T1083', 'T1070.004', 'T1027', 'T1561', 'T1583.001', 'T1562.011', 'T1140', 'T1562.004', 'T1218', 'T1201', 'T1110.004', 'T1555.004', 'T1562.001', 'T1110.001', 'T1518.001', 'T1598.004', 'T1490', 'T1021.001', 'T1537', 'T1588.001', 'T1599', 'T1486', 'T1053.005', 'T1094', 'T1059.003', 'T1553.006', 'T1059', 'T1016', 'T1555.003', 'T1556.002', 'T1657', 'T1547.001', 'T1111', 'T1087', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1218.005', 'T1136.001', 'T1597.001', 'T1485', 'T1021', 'T1555.005'}\n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 1.6850587368011474 minutes\n",
      "ttpfshot_sl: {'T1090.001', 'T1591.004', 'T1070', 'T1136.003', 'T1586.003', 'T1548.005', 'T1098.005', 'T1531', 'T1110.003', 'T1621', 'T1550.001', 'T1201', 'T1588.002', 'T1071.001', 'T1078.003', 'T1665', 'T1190', 'T1528', 'T1599', 'T1108', 'T1589.002', 'T1029', 'T1111', 'T1078', 'T1090.002', 'T1036', 'T1098.001', 'T1195.002', 'T1078.004'}\n",
      "             subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sl              0.0          0.560185  0.285714  0.175926   \n",
      "\n",
      "             f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sl     0.372549         0.231707         0.175926      0.372549   \n",
      "\n",
      "             recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sl      0.175926       0.166667       0.175926  \n",
      "min_distance: 0.8\n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 3.442954500516256 minutes\n",
      "ttpfshot_sl: {'T1567.002', 'T1560.001', 'T1102.002', 'T1219', 'T1550.002', 'T1548.003', 'T1105', 'T1076', 'T1083', 'T1070.004', 'T1027', 'T1561', 'T1110.003', 'T1583.001', 'T1562.004', 'T1218', 'T1201', 'T1110', 'T1555.004', 'T1562.001', 'T1110.001', 'T1518.001', 'T1598.004', 'T1490', 'T1021.001', 'T1537', 'T1070.001', 'T1588.001', 'T1599', 'T1486', 'T1053.005', 'T1094', 'T1059.003', 'T1553.006', 'T1059', 'T1016', 'T1555.003', 'T1556.002', 'T1657', 'T1547.001', 'T1111', 'T1087', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1218.005', 'T1136.001', 'T1597.001', 'T1555.005'}\n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 1.5899027307828268 minutes\n",
      "ttpfshot_sl: {'T1090.001', 'T1591.004', 'T1070', 'T1586.003', 'T1136.003', 'T1548.005', 'T1098.005', 'T1110.003', 'T1621', 'T1550.001', 'T1201', 'T1588.002', 'T1071.001', 'T1078.003', 'T1665', 'T1190', 'T1528', 'T1078.002', 'T1599', 'T1108', 'T1589.002', 'T1029', 'T1111', 'T1078', 'T1090.002', 'T1036', 'T1098.001', 'T1195.002', 'T1078.004'}\n",
      "             subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sl              0.0          0.557143  0.290076  0.177778   \n",
      "\n",
      "             f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sl     0.379085           0.2375         0.180952      0.372549   \n",
      "\n",
      "             recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sl       0.17619       0.169643        0.17619  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "for min_distance in [0.2,0.3,0.4,0.5,0.7,0.8]:\n",
    "    print(\"min_distance:\", min_distance)\n",
    "\n",
    "\n",
    "    #df_reports[\"ttpxhunter\"] = \"\"\n",
    "    df_reports[\"ttpfshot_sl\"] = \"\"\n",
    "    #df_reports[\"ttpfshot_ml\"] = \"\"\n",
    "    #df_reports[\"ttpfshot_zs\"] = \"\"\n",
    "\n",
    "    for index, row in df_reports.iterrows():\n",
    "        #print(f\"Index: {index}\")\n",
    "        print(\"text nr: \", index)\n",
    "\n",
    "        text_to_classify = row[\"CleanText\"]\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "        ttpfshot_sl = ttf_shot_predict(sent_tokenize(text_to_classify), \"SINGLE_LABEL2\", llm, db, distance=min_distance)\n",
    "        elapsed_time = (time.time() - start_time)/60\n",
    "        print(f\"ttpfshot_sl done in: {elapsed_time} minutes\")\n",
    "\n",
    "        '''\n",
    "        start_time = time.time()\n",
    "        ttpfshot_ml = ttf_shot_predict(sent_tokenize(text_to_classify), \"MULTIPLE_LABEL\", llm, db3)\n",
    "        elapsed_time = (time.time() - start_time)/60\n",
    "        print(f\"ttpfshot_ml done in: {elapsed_time} minutes\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        ttpfshot_zs = ttf_shot_predict(sent_tokenize(text_to_classify), \"ZERO_SHOT\", llm, db3)\n",
    "        elapsed_time = (time.time() - start_time)/60\n",
    "        print(f\"ttpfshot_zs done in: {elapsed_time} minutes\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        ttps, ttp_names = extract_ttp_from_sentences(sent_tokenize(text_to_classify), th, label_dict, ttpid2name)#(text_to_classify, th, label_dict, ttpid2name)\n",
    "        elapsed_time = (time.time() - start_time)/60\n",
    "        print(f\"ttpxhunter done in: {elapsed_time} minutes\")\n",
    "        '''\n",
    "        ### save results to the reports dataframe\n",
    "        #df_reports.at[index, 'ttpxhunter'] = ttps\n",
    "        df_reports.at[index, 'ttpfshot_sl'] = ttpfshot_sl\n",
    "        #df_reports.at[index, 'ttpfshot_ml'] = ttpfshot_ml\n",
    "        #df_reports.at[index, 'ttpfshot_zs'] = ttpfshot_zs\n",
    "\n",
    "\n",
    "        #print(\"ttpxhunter:\", ttps)\n",
    "        #print(\"ttpxhunter:\", ttps)\n",
    "        print(\"ttpfshot_sl:\", ttpfshot_sl)\n",
    "        #print(\"ttpfshot_ml:\", ttpfshot_ml)\n",
    "        #print(\"ttpZshot_zs:\", ttpfshot_zs)\n",
    "        \n",
    "    all_scores = {\n",
    "        #\"ttpxhunter\" : calculate_metrics2(df_reports, 'TTP', 'ttpxhunter', 'ttpxhunter'),\n",
    "        \"ttpfshot_sl\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_sl', 'ttpfshot_sl'),\n",
    "        #\"ttpfshot_ml\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_ml', 'ttpfshot_ml'),\n",
    "        #\"ttpfshot_zs\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_zs', 'ttpfshot_zs')\n",
    "    }\n",
    "\n",
    "    #scores_df = pd.DataFrame(all_scores)#.transpose()\n",
    "\n",
    "    #print(scores_df)\n",
    "\n",
    "    flattened_data = {outer_key: inner_dict[outer_key] for outer_key, inner_dict in all_scores.items()}\n",
    "\n",
    "    # Create DataFrame\n",
    "    scores_df = pd.DataFrame(flattened_data).transpose()\n",
    "    print(scores_df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50828272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11fbfb8d",
   "metadata": {},
   "source": [
    "### Simulate different distance tresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7c2b98d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_distance: 0.41\n",
      "text nr:  0\n",
      "ttpfshot_sl done in: 2.7276632030804953 minutes\n",
      "ttpfshot_sl: {'T1567.002', 'T1560.001', 'T1548.003', 'T1219', 'T1550.002', 'T1105', 'T0869', 'T1076', 'T1083', 'T1070.004', 'T1027', 'T1561', 'T1562.004', 'T1556', 'T1201', 'T1588.002', 'T1588', 'T1562.001', 'T1110.001', 'T1518.001', 'T1587', 'T1598.004', 'T1480.001', 'T1490', 'T1537', 'T1553', 'T1070.001', 'T1560', 'T1599', 'T1486', 'T1053.005', 'T1530', 'T1094', 'T1059.003', 'T1553.006', 'T1059', 'T1016', 'T1555.003', 'T1657', 'T1547.001', 'T1018', 'T1071.003', 'T1003.005', 'T1556.004', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1218.005', 'T1136.001', 'T1021', 'T1555.005'}\n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 1.4641175071398418 minutes\n",
      "ttpfshot_sl: {'T1591.004', 'T1210', 'T1599.001', 'T1548.005', 'T1583.003', 'T1098.005', 'T1110.003', 'T1562.011', 'T1548', 'T1621', 'T1201', 'T1588.002', 'T1071.001', 'T1078.003', 'T1193', 'T1665', 'T1190', 'T1528', 'T1108', 'T1589.002', 'T1029', 'T1189', 'T1111', 'T1078', 'T1090.002', 'T1036', 'T1098.001', 'T1195.002', 'T1535', 'T1078.004'}\n",
      "             subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sl              0.0          0.577982  0.313433  0.189602   \n",
      "\n",
      "             f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sl     0.405229         0.253012         0.188073      0.411765   \n",
      "\n",
      "             recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sl      0.192661       0.185841       0.188073  \n",
      "min_distance: 0.42\n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 2.940241769949595 minutes\n",
      "ttpfshot_sl: {'T1567.002', 'T1070', 'T1219', 'T1550.002', 'T1105', 'T1592.002', 'T0869', 'T1076', 'T1083', 'T1070.004', 'T1027', 'T1561', 'T1136.002', 'T1562.004', 'T1218', 'T1201', 'T1588.002', 'T1555.004', 'T1562.001', 'T1110.001', 'T1548.002', 'T1518.001', 'T1587', 'T1598.004', 'T1480.001', 'T1490', 'T1537', 'T1070.001', 'T1190', 'T1560', 'T1599', 'T1486', 'T1053.005', 'T1094', 'T1059.003', 'T1553.006', 'T1059', 'T1016', 'T1555.003', 'T1657', 'T1547.001', 'T1071.003', 'T1556.004', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1218.005', 'T1136.001', 'T1555.005'}\n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 1.3485962788263957 minutes\n",
      "ttpfshot_sl: {'T1591.004', 'T1210', 'T1599.001', 'T1136.003', 'T1098.005', 'T1110.003', 'T1562.011', 'T1200', 'T1621', 'T1201', 'T1550.001', 'T1588.002', 'T1071.001', 'T1078.003', 'T1193', 'T1665', 'T1528', 'T1108', 'T1589.002', 'T1029', 'T1189', 'T1078.001', 'T1111', 'T1562.008', 'T1078', 'T1090.002', 'T1036', 'T1098.001', 'T1195.002', 'T1078.004'}\n",
      "             subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sl              0.0          0.574074   0.30303  0.182099   \n",
      "\n",
      "             f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sl     0.385621         0.246914         0.180556      0.392157   \n",
      "\n",
      "             recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sl      0.185185       0.178571       0.180556  \n",
      "min_distance: 0.43\n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 2.5813935955365497 minutes\n",
      "ttpfshot_sl: {'T1567.002', 'T1560.001', 'T1102.002', 'T1219', 'T1550.002', 'T1548.003', 'T1105', 'T1610', 'T1076', 'T1083', 'T1589', 'T1070.004', 'T1027', 'T1556.009', 'T1561', 'T1556.006', 'T1140', 'T1562.004', 'T1218', 'T1201', 'T1588.002', 'T1555.004', 'T1562.001', 'T1110.001', 'T1518.001', 'T1587', 'T1598.004', 'T1480.001', 'T1490', 'T1537', 'T1070.001', 'T1190', 'T1599', 'T1486', 'T1053.005', 'T1094', 'T1059.003', 'T1553.006', 'T1059', 'T1016', 'T1555.003', 'T1529', 'T1657', 'T1547.001', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1218.005', 'T1136.001', 'T1555.005'}\n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 1.2834811409314473 minutes\n",
      "ttpfshot_sl: {'T1591.004', 'T1210', 'T1599.001', 'T1136.003', 'T1098.005', 'T1580', 'T1110.003', 'T1562.011', 'T1090', 'T1200', 'T1021.008', 'T1621', 'T1201', 'T1110', 'T1588.002', 'T1071.001', 'T1078.003', 'T1665', 'T1528', 'T1190', 'T1649', 'T1108', 'T1589.002', 'T1195', 'T1029', 'T1189', 'T1078.001', 'T1078', 'T1090.002', 'T1036', 'T1098.001', 'T1195.002', 'T1078.004'}\n",
      "             subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sl              0.0          0.572727  0.308824  0.184848   \n",
      "\n",
      "             f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sl     0.411765         0.247059         0.186364      0.411765   \n",
      "\n",
      "             recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sl      0.186364       0.182609       0.181818  \n",
      "min_distance: 0.44\n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 2.949439533551534 minutes\n",
      "ttpfshot_sl: {'T1567.002', 'T1560.001', 'T1102.002', 'T1219', 'T1550.002', 'T1548.003', 'T1105', 'T1489', 'T0869', 'T1076', 'T1083', 'T1021.002', 'T1070.004', 'T1027', 'T1556.009', 'T1562.004', 'T1218', 'T1201', 'T1588.002', 'T1098', 'T1555.004', 'T1597.002', 'T1588', 'T1562.001', 'T1110.001', 'T1548.002', 'T1518.001', 'T1598.004', 'T1563', 'T1480.001', 'T1490', 'T1537', 'T1070.001', 'T1599', 'T1486', 'T1094', 'T1059.003', 'T1553.006', 'T1059', 'T1016', 'T1555.003', 'T1657', 'T1547.001', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1218.005', 'T1136.001', 'T1555.005'}\n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 1.2805500825246174 minutes\n",
      "ttpfshot_sl: {'T1548.003', 'T1599.001', 'T1136.003', 'T1098.005', 'T1580', 'T1110.003', 'T1562.011', 'T1090', 'T1200', 'T1621', 'T1201', 'T1588.002', 'T1071.001', 'T1078.003', 'T1193', 'T1665', 'T1190', 'T1528', 'T1649', 'T1108', 'T1589.002', 'T1029', 'T1189', 'T1111', 'T1078', 'T1090.002', 'T1036', 'T1098.001', 'T1195.002', 'T1078.004'}\n",
      "             subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sl              0.0          0.564815  0.287879   0.17284   \n",
      "\n",
      "             f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sl     0.366013         0.234568         0.171296      0.372549   \n",
      "\n",
      "             recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sl      0.175926       0.168142       0.171296  \n",
      "min_distance: 0.45\n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 3.2524412433306376 minutes\n",
      "ttpfshot_sl: {'T1567.002', 'T1560.001', 'T1102.002', 'T1219', 'T1550.002', 'T1548.003', 'T1070', 'T1105', 'T1076', 'T1083', 'T1021.002', 'T1070.004', 'T1027', 'T1110.003', 'T1562.004', 'T1218', 'T1201', 'T1098', 'T1555.004', 'T1597.002', 'T1588', 'T1562.001', 'T1110.001', 'T1518.001', 'T1598.004', 'T1563', 'T1480.001', 'T1490', 'T1070.001', 'T1190', 'T1588.001', 'T1599', 'T1486', 'T1053.005', 'T1094', 'T1059.003', 'T1553.006', 'T1059', 'T1016', 'T1555.003', 'T1657', 'T1547.001', 'T1556.004', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1218.005', 'T1136.001', 'T1555.005'}\n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 1.4966878016789755 minutes\n",
      "ttpfshot_sl: {'T1548.003', 'T1136.003', 'T1498', 'T1098.005', 'T1110.003', 'T1090', 'T1200', 'T1021.008', 'T1621', 'T1588.002', 'T1071.001', 'T1078.003', 'T1193', 'T1665', 'T1190', 'T1528', 'T1649', 'T1108', 'T1589.002', 'T1029', 'T1657', 'T1111', 'T1078', 'T1090.002', 'T1036', 'T1098.001', 'T1562.002', 'T1195.002', 'T1046', 'T1078.004'}\n",
      "             subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sl              0.0          0.551402  0.272727  0.165109   \n",
      "\n",
      "             f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sl     0.346405         0.222222         0.163551      0.352941   \n",
      "\n",
      "             recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sl      0.168224       0.157895       0.163551  \n",
      "min_distance: 0.46\n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 2.7713734189669292 minutes\n",
      "ttpfshot_sl: {'T1567.002', 'T1102.002', 'T1219', 'T1550.002', 'T1548.003', 'T1105', 'T1076', 'T1083', 'T1070.004', 'T1027', 'T1110.003', 'T1562.004', 'T1218', 'T1201', 'T1098', 'T1597.002', 'T1588', 'T1562.001', 'T1110.001', 'T1518.001', 'T1587', 'T1598.004', 'T1563', 'T1490', 'T1021.001', 'T1537', 'T1588.001', 'T1560', 'T1599', 'T1486', 'T1053.005', 'T1094', 'T1059.003', 'T1553.006', 'T1059', 'T1016', 'T1555.003', 'T1657', 'T1547.001', 'T1003.005', 'T1087', 'T1556.004', 'T1562.009', 'T1591', 'T1218.005', 'T1048.003', 'T1069.002', 'T1136.001', 'T1555.005'}\n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 1.6152965784072877 minutes\n",
      "ttpfshot_sl: {'T1548.003', 'T1070', 'T1136.003', 'T1498', 'T1098.005', 'T1110.003', 'T1090', 'T1021.008', 'T1621', 'T1201', 'T1588.002', 'T1071.001', 'T1078.003', 'T1193', 'T1665', 'T1190', 'T1528', 'T1078.002', 'T1599', 'T1649', 'T1108', 'T1589.002', 'T1029', 'T1657', 'T1111', 'T1078', 'T1090.002', 'T1036', 'T1098.001', 'T1195.002', 'T1078.004'}\n",
      "             subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sl              0.0          0.558252  0.305344  0.190939   \n",
      "\n",
      "             f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sl     0.385621             0.25          0.18932      0.392157   \n",
      "\n",
      "             recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sl      0.194175        0.18018        0.18932  \n",
      "min_distance: 0.47\n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttpfshot_sl done in: 2.8237418214480083 minutes\n",
      "ttpfshot_sl: {'T1567.002', 'T1560.001', 'T1102.002', 'T1219', 'T1550.002', 'T1548.003', 'T1105', 'T0869', 'T1076', 'T1083', 'T1070.004', 'T1027', 'T1561', 'T1110.003', 'T1562.004', 'T1218', 'T1556', 'T1201', 'T1110.004', 'T1597.002', 'T1588', 'T1562.001', 'T1110.001', 'T1548.002', 'T1518.001', 'T1587', 'T1598.004', 'T1563', 'T1490', 'T1021.001', 'T1537', 'T1588.001', 'T1599', 'T1486', 'T1094', 'T1059.003', 'T1553.006', 'T1059', 'T1016', 'T1555.003', 'T1657', 'T1547.001', 'T1111', 'T1003.005', 'T1087', 'T1562.009', 'T1591', 'T1055.001', 'T1048.003', 'T1069.002', 'T1218.005', 'T1136.001', 'T1555.005'}\n",
      "text nr:  1\n",
      "ttpfshot_sl done in: 1.374034051100413 minutes\n",
      "ttpfshot_sl: {'T1591.004', 'T1548.003', 'T1070', 'T1136.003', 'T1498', 'T1098.005', 'T1110.003', 'T1090', 'T1021.008', 'T1621', 'T1201', 'T1588.002', 'T1071.001', 'T1078.003', 'T1193', 'T1665', 'T1190', 'T1528', 'T1078.002', 'T1599', 'T1649', 'T1108', 'T1589.002', 'T1029', 'T1078', 'T1090.002', 'T1036', 'T1098.001', 'T1195.002', 'T1078.004'}\n",
      "             subset_accuracy  hamming_accuracy  f1_micro  f1_macro  \\\n",
      "ttpfshot_sl              0.0          0.555556  0.283582  0.175926   \n",
      "\n",
      "             f1_weighted  precision_micro  precision_macro  recall_micro  \\\n",
      "ttpfshot_sl     0.372549         0.228916         0.175926      0.372549   \n",
      "\n",
      "             recall_macro  jaccard_micro  jaccard_macro  \n",
      "ttpfshot_sl      0.175926       0.165217       0.175926  \n",
      "min_distance: 0.48\n",
      "text nr:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hamzicd/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m text_to_classify \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCleanText\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     17\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 18\u001b[0m ttpfshot_sl \u001b[38;5;241m=\u001b[39m \u001b[43mttf_shot_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_to_classify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSINGLE_LABEL2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mttpfshot_sl done in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[110], line 14\u001b[0m, in \u001b[0;36mttf_shot_predict\u001b[0;34m(sentences, option, llm, db, distance)\u001b[0m\n\u001b[1;32m     12\u001b[0m     predicted_label \u001b[38;5;241m=\u001b[39m predict_label1(sentence, db, llm)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSINGLE_LABEL2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 14\u001b[0m     predicted_label \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_label12\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# multiple label\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMULTIPLE_LABEL\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Cell \u001b[0;32mIn[111], line 128\u001b[0m, in \u001b[0;36mpredict_label12\u001b[0;34m(text_to_predict, train_vector_db, llm, distance)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m#####\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m#**Think through the classification process step-by-step, comparing the 'InputText' to each example, but do not share your reasoning.**\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m#print(xs)\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m#print(doc_counter)\u001b[39;00m\n\u001b[1;32m    127\u001b[0m prompt \u001b[38;5;241m=\u001b[39m xs\n\u001b[0;32m--> 128\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted_label\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    285\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    647\u001b[0m ]\n\u001b[1;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 633\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m         )\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:689\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 689\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/openai/resources/chat/completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/openai/_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1277\u001b[0m     )\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/openai/_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1043\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/openai/_base_client.py:1093\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/openai/_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1043\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/openai/_base_client.py:1093\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/openai/_base_client.py:1059\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1058\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1062\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1063\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1068\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "for min_distance in [0.41,0.42,0.43,0.44,0.45,0.46,0.47,0.48]:\n",
    "    print(\"min_distance:\", min_distance)\n",
    "\n",
    "\n",
    "    #df_reports[\"ttpxhunter\"] = \"\"\n",
    "    df_reports[\"ttpfshot_sl\"] = \"\"\n",
    "    #df_reports[\"ttpfshot_ml\"] = \"\"\n",
    "    #df_reports[\"ttpfshot_zs\"] = \"\"\n",
    "\n",
    "    for index, row in df_reports.iterrows():\n",
    "        #print(f\"Index: {index}\")\n",
    "        print(\"text nr: \", index)\n",
    "\n",
    "        text_to_classify = row[\"CleanText\"]\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "        ttpfshot_sl = ttf_shot_predict(sent_tokenize(text_to_classify), \"SINGLE_LABEL2\", llm, db, distance=min_distance)\n",
    "        elapsed_time = (time.time() - start_time)/60\n",
    "        print(f\"ttpfshot_sl done in: {elapsed_time} minutes\")\n",
    "\n",
    "        '''\n",
    "        start_time = time.time()\n",
    "        ttpfshot_ml = ttf_shot_predict(sent_tokenize(text_to_classify), \"MULTIPLE_LABEL\", llm, db3)\n",
    "        elapsed_time = (time.time() - start_time)/60\n",
    "        print(f\"ttpfshot_ml done in: {elapsed_time} minutes\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        ttpfshot_zs = ttf_shot_predict(sent_tokenize(text_to_classify), \"ZERO_SHOT\", llm, db3)\n",
    "        elapsed_time = (time.time() - start_time)/60\n",
    "        print(f\"ttpfshot_zs done in: {elapsed_time} minutes\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        ttps, ttp_names = extract_ttp_from_sentences(sent_tokenize(text_to_classify), th, label_dict, ttpid2name)#(text_to_classify, th, label_dict, ttpid2name)\n",
    "        elapsed_time = (time.time() - start_time)/60\n",
    "        print(f\"ttpxhunter done in: {elapsed_time} minutes\")\n",
    "        '''\n",
    "        ### save results to the reports dataframe\n",
    "        #df_reports.at[index, 'ttpxhunter'] = ttps\n",
    "        df_reports.at[index, 'ttpfshot_sl'] = ttpfshot_sl\n",
    "        #df_reports.at[index, 'ttpfshot_ml'] = ttpfshot_ml\n",
    "        #df_reports.at[index, 'ttpfshot_zs'] = ttpfshot_zs\n",
    "\n",
    "\n",
    "        #print(\"ttpxhunter:\", ttps)\n",
    "        #print(\"ttpxhunter:\", ttps)\n",
    "        print(\"ttpfshot_sl:\", ttpfshot_sl)\n",
    "        #print(\"ttpfshot_ml:\", ttpfshot_ml)\n",
    "        #print(\"ttpZshot_zs:\", ttpfshot_zs)\n",
    "        \n",
    "    all_scores = {\n",
    "        #\"ttpxhunter\" : calculate_metrics2(df_reports, 'TTP', 'ttpxhunter', 'ttpxhunter'),\n",
    "        \"ttpfshot_sl\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_sl', 'ttpfshot_sl'),\n",
    "        #\"ttpfshot_ml\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_ml', 'ttpfshot_ml'),\n",
    "        #\"ttpfshot_zs\" : calculate_metrics2(df_reports, 'TTP', 'ttpfshot_zs', 'ttpfshot_zs')\n",
    "    }\n",
    "\n",
    "    #scores_df = pd.DataFrame(all_scores)#.transpose()\n",
    "\n",
    "    #print(scores_df)\n",
    "\n",
    "    flattened_data = {outer_key: inner_dict[outer_key] for outer_key, inner_dict in all_scores.items()}\n",
    "\n",
    "    # Create DataFrame\n",
    "    scores_df = pd.DataFrame(flattened_data).transpose()\n",
    "    print(scores_df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a118f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
